{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e78d139aadb04118805c5b629c13d5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df1320b5c5b14e1f9a52ea64a576d00e",
              "IPY_MODEL_f3160d5ae44c4f3ca1e152bc6a25cf90",
              "IPY_MODEL_80a533b534604056b065d7a27cbca492"
            ],
            "layout": "IPY_MODEL_210f64dfba3f4471ad2f862a1e0a8db4"
          }
        },
        "df1320b5c5b14e1f9a52ea64a576d00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d888eb79b4e24ba990c367c3235c4710",
            "placeholder": "​",
            "style": "IPY_MODEL_0edcc2f578064270abd01ba9f2bdcbd9",
            "value": "config.json: 100%"
          }
        },
        "f3160d5ae44c4f3ca1e152bc6a25cf90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1a94f39e9f4b6f92252d7bcc6bbc8d",
            "max": 855,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec78c251118546adb5a3f50ca8235940",
            "value": 855
          }
        },
        "80a533b534604056b065d7a27cbca492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b1a3d280f9148edaed3917308a87bd5",
            "placeholder": "​",
            "style": "IPY_MODEL_6c35edb7cd2740beb40d42ad7a994853",
            "value": " 855/855 [00:00&lt;00:00, 60.6kB/s]"
          }
        },
        "210f64dfba3f4471ad2f862a1e0a8db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d888eb79b4e24ba990c367c3235c4710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edcc2f578064270abd01ba9f2bdcbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1a94f39e9f4b6f92252d7bcc6bbc8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec78c251118546adb5a3f50ca8235940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b1a3d280f9148edaed3917308a87bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c35edb7cd2740beb40d42ad7a994853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93ec26a093ec4595a58e919e8d4379e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_238a96c8b87a4168b0a8f4306d00b1a3",
              "IPY_MODEL_1cd26d5e38664798b57d6b84d3560bc4",
              "IPY_MODEL_3a22812976904e65befa066b255c27b9"
            ],
            "layout": "IPY_MODEL_dfaa090bdc0f4eb785dc69b9a7848972"
          }
        },
        "238a96c8b87a4168b0a8f4306d00b1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec86e9291b414ffdb6fd1a5c75e9dbfe",
            "placeholder": "​",
            "style": "IPY_MODEL_282f8628e3ba460d8f510552ae3c33d1",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "1cd26d5e38664798b57d6b84d3560bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b36ec081b7094e94855509223c7fba5b",
            "max": 90558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94f0cd1fb805454f8de2141ce628ce78",
            "value": 90558
          }
        },
        "3a22812976904e65befa066b255c27b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eddd2cfe907e41de86c4bcff67d5c5a1",
            "placeholder": "​",
            "style": "IPY_MODEL_7cbde966d9d4472084dd281cc3ce5bf6",
            "value": " 90.6k/90.6k [00:00&lt;00:00, 8.10MB/s]"
          }
        },
        "dfaa090bdc0f4eb785dc69b9a7848972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec86e9291b414ffdb6fd1a5c75e9dbfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282f8628e3ba460d8f510552ae3c33d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b36ec081b7094e94855509223c7fba5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f0cd1fb805454f8de2141ce628ce78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eddd2cfe907e41de86c4bcff67d5c5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbde966d9d4472084dd281cc3ce5bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a07b00ccac954e4d895a637f18ca9774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8019b854428e4379bdd2f0e3566df599",
              "IPY_MODEL_c3385c1a3c70414792660d8a7d99f121",
              "IPY_MODEL_6a7ab6e5be1c43cd95d058922111f170"
            ],
            "layout": "IPY_MODEL_6ccdfcebd330487fb6351000549eab30"
          }
        },
        "8019b854428e4379bdd2f0e3566df599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35f4a54e7b4344f4a8eff4524352aed3",
            "placeholder": "​",
            "style": "IPY_MODEL_32a8324f06534b6dbc34819c1d013cd4",
            "value": "Fetching 2 files: 100%"
          }
        },
        "c3385c1a3c70414792660d8a7d99f121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eb897b616804603a4f750e4d4e9aa10",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5984f06117ad49fd8af5838f75bb394c",
            "value": 2
          }
        },
        "6a7ab6e5be1c43cd95d058922111f170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_775730b30eb94ab38e4fdb612cc0a442",
            "placeholder": "​",
            "style": "IPY_MODEL_9372e092a9e8441aae72cd8bac76dbd6",
            "value": " 2/2 [00:52&lt;00:00, 52.26s/it]"
          }
        },
        "6ccdfcebd330487fb6351000549eab30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f4a54e7b4344f4a8eff4524352aed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a8324f06534b6dbc34819c1d013cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1eb897b616804603a4f750e4d4e9aa10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5984f06117ad49fd8af5838f75bb394c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "775730b30eb94ab38e4fdb612cc0a442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9372e092a9e8441aae72cd8bac76dbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca26e2b3aa8a4202bde0385eab31b51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29747d46ac5142e481ca04bef207dc85",
              "IPY_MODEL_a3303098633642ce941a19fdfe3c29a9",
              "IPY_MODEL_fbe2076dec73413e8a22944a009a30ed"
            ],
            "layout": "IPY_MODEL_22c06a1f42e24a99a7dc18a7d373c383"
          }
        },
        "29747d46ac5142e481ca04bef207dc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a40a2586464bb7954402b0acc24c1c",
            "placeholder": "​",
            "style": "IPY_MODEL_1b152bb8cf4b44efa37631fccd2ec0ed",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "a3303098633642ce941a19fdfe3c29a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7152b307e7ea4f999d550ed2664f93fd",
            "max": 4961251752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8c2f53076654f98b99e2a6bc0cab3d7",
            "value": 4961251752
          }
        },
        "fbe2076dec73413e8a22944a009a30ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db7dec6260ea426c985b9833fedb1e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_0ae9eec48d1c48e58a5a8e31ccc7dc5c",
            "value": " 4.96G/4.96G [00:51&lt;00:00, 99.9MB/s]"
          }
        },
        "22c06a1f42e24a99a7dc18a7d373c383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a40a2586464bb7954402b0acc24c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b152bb8cf4b44efa37631fccd2ec0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7152b307e7ea4f999d550ed2664f93fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c2f53076654f98b99e2a6bc0cab3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db7dec6260ea426c985b9833fedb1e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae9eec48d1c48e58a5a8e31ccc7dc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c18338b3bff470b926662c5e8a1e70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52994d841f6c491fb870ac1477a970fb",
              "IPY_MODEL_3f4ee498fbc1478ea6541b19da399779",
              "IPY_MODEL_7c18a70f602247f18b992d91515c3c38"
            ],
            "layout": "IPY_MODEL_f1b29d7af0f84b54bc75403ba4b548b6"
          }
        },
        "52994d841f6c491fb870ac1477a970fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d90ee41cb94f5a9181c89bff117e2e",
            "placeholder": "​",
            "style": "IPY_MODEL_b60c2c80088b4cf99cd58b72794042bb",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "3f4ee498fbc1478ea6541b19da399779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d24db9bcfc409698b037ed2ea2a410",
            "max": 3639026128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c51beab3a4a49ad8bec1f8165edef81",
            "value": 3639026128
          }
        },
        "7c18a70f602247f18b992d91515c3c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95ddd0c042d540309e89f7d9bf8779eb",
            "placeholder": "​",
            "style": "IPY_MODEL_5c42906f31be459a884a1a36667a88f2",
            "value": " 3.64G/3.64G [00:42&lt;00:00, 106MB/s]"
          }
        },
        "f1b29d7af0f84b54bc75403ba4b548b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22d90ee41cb94f5a9181c89bff117e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b60c2c80088b4cf99cd58b72794042bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18d24db9bcfc409698b037ed2ea2a410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c51beab3a4a49ad8bec1f8165edef81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95ddd0c042d540309e89f7d9bf8779eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c42906f31be459a884a1a36667a88f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00ce8febf67b45f6a6d8031f6cfbbc34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7869a25f5f6c454ea76e32c17e51aff9",
              "IPY_MODEL_7f727e71986e48c0aa62df073dca952f",
              "IPY_MODEL_c3d6f630f200448f877e0c419f1cb151"
            ],
            "layout": "IPY_MODEL_640e0364fbc54d27a2fc1d83eaf511e5"
          }
        },
        "7869a25f5f6c454ea76e32c17e51aff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_505c01bf724f43c6911b6335883e235a",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e4b0c6a83740098fa6b5ebb7b26074",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7f727e71986e48c0aa62df073dca952f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf7803a6ac84172b0c5a8b15c6d7094",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60ad24e075f04b4d85ae7d2b0e414642",
            "value": 2
          }
        },
        "c3d6f630f200448f877e0c419f1cb151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54433e4c821440aba3cf74612a5ba4ae",
            "placeholder": "​",
            "style": "IPY_MODEL_3bf8dabfc3fc43809152792a17e47e4a",
            "value": " 2/2 [00:36&lt;00:00, 17.76s/it]"
          }
        },
        "640e0364fbc54d27a2fc1d83eaf511e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "505c01bf724f43c6911b6335883e235a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e4b0c6a83740098fa6b5ebb7b26074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccf7803a6ac84172b0c5a8b15c6d7094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60ad24e075f04b4d85ae7d2b0e414642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54433e4c821440aba3cf74612a5ba4ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf8dabfc3fc43809152792a17e47e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a175e7368a9d4181b0c20185e26a94b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bfa588f3fea4f209b33dc7af7abb855",
              "IPY_MODEL_ecb6fb54807c48638d5e1df63e7f31e2",
              "IPY_MODEL_c1ace91385574e9da47a5f0f3fc7e4b0"
            ],
            "layout": "IPY_MODEL_8ec154ab44b04b329e60266117f7e62c"
          }
        },
        "5bfa588f3fea4f209b33dc7af7abb855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a23982d5aa204e35b1878f07cb34018b",
            "placeholder": "​",
            "style": "IPY_MODEL_d197739a9fb34c6cace2927e5ea120f9",
            "value": "generation_config.json: 100%"
          }
        },
        "ecb6fb54807c48638d5e1df63e7f31e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a06a0cee354aeb8825010fe5884574",
            "max": 215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e5d0c62aa22438cb8f1b16026df0f30",
            "value": 215
          }
        },
        "c1ace91385574e9da47a5f0f3fc7e4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40024186496e4005a08c3074eb4b1893",
            "placeholder": "​",
            "style": "IPY_MODEL_03f67b6fcce04c6c90c7a0d348bd7a08",
            "value": " 215/215 [00:00&lt;00:00, 20.1kB/s]"
          }
        },
        "8ec154ab44b04b329e60266117f7e62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23982d5aa204e35b1878f07cb34018b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d197739a9fb34c6cace2927e5ea120f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25a06a0cee354aeb8825010fe5884574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e5d0c62aa22438cb8f1b16026df0f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40024186496e4005a08c3074eb4b1893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f67b6fcce04c6c90c7a0d348bd7a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ec5230219a7482d9ce85309c95151b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bbb4ff97e05405688f6628860262989",
              "IPY_MODEL_da69c2ffd07849eaa9f73ed5a52a8f30",
              "IPY_MODEL_09f570515e664e71b57e3f5465cc9001"
            ],
            "layout": "IPY_MODEL_1e89eb857ef14110a53569c45ca1ec49"
          }
        },
        "6bbb4ff97e05405688f6628860262989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfd66dc6801b404d9d4021e87563eb17",
            "placeholder": "​",
            "style": "IPY_MODEL_7debc5f1aecd42feaecb03dd25c30ded",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "da69c2ffd07849eaa9f73ed5a52a8f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71b9991e5ee040bfa0f9345abb58ec2a",
            "max": 1156999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4433eaa001e8493298a9bbbc384a8991",
            "value": 1156999
          }
        },
        "09f570515e664e71b57e3f5465cc9001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23fe33f9f18447fb9954f1e028f36278",
            "placeholder": "​",
            "style": "IPY_MODEL_500725f92cb14eda8b8454b43d1fc5b8",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 55.4MB/s]"
          }
        },
        "1e89eb857ef14110a53569c45ca1ec49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd66dc6801b404d9d4021e87563eb17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7debc5f1aecd42feaecb03dd25c30ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71b9991e5ee040bfa0f9345abb58ec2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4433eaa001e8493298a9bbbc384a8991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23fe33f9f18447fb9954f1e028f36278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500725f92cb14eda8b8454b43d1fc5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "539eda85ee37444784b4b76c130922c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_796fe5334db84bcb8113a2ebcde22868",
              "IPY_MODEL_ba1dadc8f1bc4cf682cfe8fb9fa874cd",
              "IPY_MODEL_84690cf70ab74fc6b6e2dd7efcf0434c"
            ],
            "layout": "IPY_MODEL_8a1571ded10c487793452399bd5b1e9a"
          }
        },
        "796fe5334db84bcb8113a2ebcde22868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ed343ab1c64e22ad13eb9291f8b5bc",
            "placeholder": "​",
            "style": "IPY_MODEL_4cfc9c1839f247bfaabe946db4fa786e",
            "value": "tokenizer.model: 100%"
          }
        },
        "ba1dadc8f1bc4cf682cfe8fb9fa874cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563da134116240a284b0319304158019",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ab65fafb8e043a29f9366b8d7bcddcc",
            "value": 4689074
          }
        },
        "84690cf70ab74fc6b6e2dd7efcf0434c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47bc9498e3c548c2b9e1f7efd1e9a936",
            "placeholder": "​",
            "style": "IPY_MODEL_08e7ac6ba1ee45048aa75beecbc36b08",
            "value": " 4.69M/4.69M [00:00&lt;00:00, 69.2MB/s]"
          }
        },
        "8a1571ded10c487793452399bd5b1e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ed343ab1c64e22ad13eb9291f8b5bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cfc9c1839f247bfaabe946db4fa786e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "563da134116240a284b0319304158019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab65fafb8e043a29f9366b8d7bcddcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47bc9498e3c548c2b9e1f7efd1e9a936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e7ac6ba1ee45048aa75beecbc36b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "360d90ac9cf64300923825a808be9361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7170cf0e9e6549c6abd4c33319165dc9",
              "IPY_MODEL_eb7a98ce1d2843fc8fa02a0ac16ffcc2",
              "IPY_MODEL_4937f65babdd4dffae6bbdc192b19a32"
            ],
            "layout": "IPY_MODEL_8a1f2f6d46814ff1b301daec9e42fb06"
          }
        },
        "7170cf0e9e6549c6abd4c33319165dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6420d97af71c4691b2fdb4939b42900b",
            "placeholder": "​",
            "style": "IPY_MODEL_6e6af60efd414989b93a7c1133aca25a",
            "value": "tokenizer.json: 100%"
          }
        },
        "eb7a98ce1d2843fc8fa02a0ac16ffcc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58ec8df50b744ab2a9eeadb695795d40",
            "max": 33384568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1245f7ba07fa441ab198ff5175037a95",
            "value": 33384568
          }
        },
        "4937f65babdd4dffae6bbdc192b19a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_438846de09b7404cac652f8b13d37984",
            "placeholder": "​",
            "style": "IPY_MODEL_a0d2859e74b04713bb22c9b5be3b5cb3",
            "value": " 33.4M/33.4M [00:00&lt;00:00, 128MB/s]"
          }
        },
        "8a1f2f6d46814ff1b301daec9e42fb06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6420d97af71c4691b2fdb4939b42900b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6af60efd414989b93a7c1133aca25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58ec8df50b744ab2a9eeadb695795d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1245f7ba07fa441ab198ff5175037a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "438846de09b7404cac652f8b13d37984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d2859e74b04713bb22c9b5be3b5cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d5e875247314e74802d4d453f39cafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab19c4934687428fba0f1a74075d8016",
              "IPY_MODEL_7587f7f0038f468c8c08242793bdbff0",
              "IPY_MODEL_dbab1776d4564c1b8b0961053fbb57af"
            ],
            "layout": "IPY_MODEL_eae40a27075b4c52bb6594d3478fb9bd"
          }
        },
        "ab19c4934687428fba0f1a74075d8016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c664eaeebcb4638b8e7c12926011142",
            "placeholder": "​",
            "style": "IPY_MODEL_d1f27f08338a4acaae06aca9a9ff391b",
            "value": "added_tokens.json: 100%"
          }
        },
        "7587f7f0038f468c8c08242793bdbff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7410c5de4994c2790cd106c340e4ecc",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19d949567efa4cefb7c740296513de68",
            "value": 35
          }
        },
        "dbab1776d4564c1b8b0961053fbb57af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_374f86ffdd27452290ad3a4abc9c25c3",
            "placeholder": "​",
            "style": "IPY_MODEL_df700a23ff6e4634a3ddad500a13e073",
            "value": " 35.0/35.0 [00:00&lt;00:00, 2.99kB/s]"
          }
        },
        "eae40a27075b4c52bb6594d3478fb9bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c664eaeebcb4638b8e7c12926011142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f27f08338a4acaae06aca9a9ff391b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7410c5de4994c2790cd106c340e4ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d949567efa4cefb7c740296513de68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "374f86ffdd27452290ad3a4abc9c25c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df700a23ff6e4634a3ddad500a13e073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b946e8470234fab9350b27dfafe49ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25eb61c29095424292ea582de4971548",
              "IPY_MODEL_b95be68026b04cfe9d1f7ab382e61e32",
              "IPY_MODEL_c0cb7b723009415683474695c610cbe3"
            ],
            "layout": "IPY_MODEL_19768ae18dcd4deca0309196085035da"
          }
        },
        "25eb61c29095424292ea582de4971548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a7e9d31d3614038b4933debe60de878",
            "placeholder": "​",
            "style": "IPY_MODEL_98e90c1dc3f54940b60c7b860641b9db",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b95be68026b04cfe9d1f7ab382e61e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d91cfce36b44993ac35997d2fb19c90",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03d6cedda65c44239667be2c4e928e91",
            "value": 662
          }
        },
        "c0cb7b723009415683474695c610cbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10369455c9e6432ea3715d53652a0407",
            "placeholder": "​",
            "style": "IPY_MODEL_a4ef333ec81549ce9b25a246d3b3c1ce",
            "value": " 662/662 [00:00&lt;00:00, 72.6kB/s]"
          }
        },
        "19768ae18dcd4deca0309196085035da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7e9d31d3614038b4933debe60de878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e90c1dc3f54940b60c7b860641b9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d91cfce36b44993ac35997d2fb19c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d6cedda65c44239667be2c4e928e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10369455c9e6432ea3715d53652a0407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ef333ec81549ce9b25a246d3b3c1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaskiratSingh10/CS503/blob/main/EvalAI2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lbXFhIIHvKR",
        "outputId": "1ed47ed9-5612-417c-d659-6b9af8384e72",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting PdfReader\n",
            "  Downloading pdfreader-0.1.15-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting bitarray>=1.1.0 (from PdfReader)\n",
            "  Downloading bitarray-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from PdfReader) (11.1.0)\n",
            "Collecting pycryptodome>=3.9.9 (from PdfReader)\n",
            "  Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from PdfReader) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->PdfReader) (1.17.0)\n",
            "Downloading pdfreader-0.1.15-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitarray-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.2/306.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitarray, pycryptodome, PdfReader\n",
            "Successfully installed PdfReader-0.1.15 bitarray-3.3.0 pycryptodome-3.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade torch torchvision torchaudio\n",
        "# !pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "A7i3Jmu0YwyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIBRARY IMPORTS"
      ],
      "metadata": {
        "id": "bJArYYLXvWWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import re"
      ],
      "metadata": {
        "id": "Eo_jLo4jHszk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for summarization\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "gq5DiOE31vxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ],
      "metadata": {
        "id": "SX-Lw5kkEnXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq8Yf2Xh15SK",
        "outputId": "e93ae47e-a5be-47aa-c246-5b27f31d02be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting PDF Text"
      ],
      "metadata": {
        "id": "nh4hPv9vvcof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pdf_text(pdf_path):\n",
        "    full_text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in reader.pages:\n",
        "                text = page.extract_text()\n",
        "                if text:\n",
        "                    full_text += text + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from PDF: {e}\")\n",
        "\n",
        "    return full_text\n"
      ],
      "metadata": {
        "id": "ImeI0Ov9sbcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload PDF"
      ],
      "metadata": {
        "id": "2igOonfPrzB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = \"/content/R008.pdf\"  # Replace with your PDF file path\n",
        "text = extract_pdf_text(pdf_file)\n",
        "print(\"Extracted Text:\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjEEtE-abwKM",
        "outputId": "0408f154-4dd4-4481-b5cc-1d8cc7f2f9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            "Advanced techniques for through and contextually\n",
            "Interpreting Noun-Noun Compounds\n",
            "Abstract\n",
            "This study examines the effectiveness of transfer learning and multi-task learning\n",
            "in the context of a complex semantic classification problem: understanding the\n",
            "meaning of noun-noun compounds. Through a series of detailed experiments and\n",
            "an in-depth analysis of errors, we demonstrate that employing transfer learning by\n",
            "initializing parameters and multi-task learning through parameter sharing enables a\n",
            "neural classification model to better generalize across a dataset characterized by a\n",
            "highly uneven distribution of semantic relationships. Furthermore, we illustrate\n",
            "how utilizing dual annotations, which involve two distinct sets of relations applied\n",
            "to the same compounds, can enhance the overall precision of a neural classifier and\n",
            "improve its F1 scores for less common yet more challenging semantic relations.\n",
            "1 Introduction\n",
            "Noun-noun compound interpretation involves determining the semantic connection between two\n",
            "nouns (or noun phrases in multi-word compounds). For instance, in the compound \"street protest,\"\n",
            "the task is to identify the semantic relationship between \"street\" and \"protest,\" which is a locative\n",
            "relation in this example. Given the prevalence of noun-noun compounds in natural language and its\n",
            "significance to other natural language processing (NLP) tasks like question answering and information\n",
            "retrieval, understanding noun-noun compounds has been extensively studied in theoretical linguistics,\n",
            "psycholinguistics, and computational linguistics.\n",
            "In computational linguistics, noun-noun compound interpretation is typically treated as an automatic\n",
            "classification task. Various machine learning (ML) algorithms and models, such as Maximum\n",
            "Entropy, Support Vector Machines, and Neural Networks, have been employed to decipher the\n",
            "semantics of nominal compounds. These models utilize information from lexical semantics, like\n",
            "WordNet-based features, and distributional semantics, such as word embeddings. However, noun-\n",
            "noun compound interpretation remains a challenging NLP problem due to the high productivity\n",
            "of noun-noun compounding as a linguistic structure and the difficulty in deriving the semantics of\n",
            "noun-noun compounds from their constituents. Our research contributes to advancing NLP research\n",
            "on noun-noun compound interpretation through the application of transfer and multi-task learning.\n",
            "The application of transfer learning (TL) and multi-task learning (MTL) in NLP has gained significant\n",
            "attention in recent years, yielding varying outcomes based on the specific tasks, model architectures,\n",
            "and datasets involved. These varying results, combined with the fact that neither TL nor MTL has\n",
            "been previously applied to noun-noun compound interpretation, motivate our thorough empirical\n",
            "investigation into the use of TL and MTL for this task. Our aim is not only to add to the existing\n",
            "research on the effectiveness of TL and MTL for semantic NLP tasks generally but also to ascertain\n",
            "their specific advantages for compound interpretation.\n",
            "A key reason for utilizing multi-task learning is to enhance generalization by making use of the\n",
            "domain-specific details present in the training data of related tasks. In this study, we demonstrate that\n",
            "TL and MTL can serve as a form of regularization, enabling the prediction of infrequent relations\n",
            "within a dataset marked by a highly skewed distribution of relations. This dataset is particularly\n",
            "well-suited for TL and MTL experimentation, as elaborated in Section 3.\n",
            "Our contributions are summarized as follows:\n",
            "1. Through meticulous analysis of results, we discover that TL and MTL, especially when applied\n",
            "to the embedding layer, enhance overall accuracy and F1 scores for less frequent relations in a\n",
            "highly skewed dataset, compared to a robust single-task learning baseline. 2. Although our research\n",
            "concentrates on TL and MTL, we present, to our knowledge, the first experimental results on the\n",
            "relatively recent dataset from Fares (2016).\n",
            "2 Related Work\n",
            "Approaches to interpreting noun-noun compounds differ based on the classification of compound\n",
            "relations, as well as the machine learning models and features employed to learn these relations. For\n",
            "instance, some define a broad set of relations, while others employ a more detailed classification.\n",
            "Some researchers challenge the idea that noun-noun compounds can be interpreted using a fixed,\n",
            "predetermined set of relations, proposing alternative methods based on paraphrasing. We center\n",
            "our attention on methods that frame the interpretation problem as a classification task involving a\n",
            "fixed, predetermined set of relations. Various machine learning models have been applied to this\n",
            "task, including nearest neighbor classifiers that use semantic similarity based on lexical resources,\n",
            "kernel-based methods like SVMs that utilize lexical and relational features, Maximum Entropy\n",
            "models that incorporate a wide range of lexical and surface form features, and neural networks that\n",
            "rely on word embeddings or combine word embeddings with path embeddings. Among these studies,\n",
            "some have utilized the same dataset. To our knowledge, TL and MTL have not been previously\n",
            "applied to compound interpretation. Therefore, we review prior research on TL and MTL in other\n",
            "NLP tasks.\n",
            "Several recent studies have conducted extensive experiments on the application of TL and MTL to a\n",
            "variety of NLP tasks, such as named entity recognition, semantic labeling, sentence-level sentiment\n",
            "classification, super-tagging, chunking, and semantic dependency parsing. The consensus among\n",
            "these studies is that the advantages of TL and MTL are largely contingent on the characteristics of the\n",
            "tasks involved, including the unevenness of the data distribution, the semantic relatedness between\n",
            "the source and target tasks, the learning trajectory of the auxiliary and main tasks (where target tasks\n",
            "that quickly reach a plateau benefit most from non-plateauing auxiliary tasks), and the structural\n",
            "similarity between the tasks. Besides differing in the NLP tasks they investigate, the aforementioned\n",
            "studies employ slightly varied definitions of TL and MTL. Our research aligns with certain studies in\n",
            "that we apply TL and MTL to learn different semantic annotations of noun-noun compounds using\n",
            "the same dataset. However, our experimental design is more akin to other work in that we experiment\n",
            "with initializing parameters across all layers of the neural network and concurrently train a single\n",
            "MTL model on two sets of relations.\n",
            "3 Task Definition and Dataset\n",
            "The objective of this task is to train a model to categorize the semantic relationships between pairs\n",
            "of nouns in a labeled dataset, where each pair forms a noun-noun compound. The complexity of\n",
            "this task is influenced by factors such as the label set used and its distribution. For the experiments\n",
            "detailed in this paper, we utilize a noun-noun compounds dataset that features compounds annotated\n",
            "with two distinct taxonomies of relations. This means that each noun-noun compound is associated\n",
            "with two different relations, each based on different linguistic theories. This dataset is derived from\n",
            "established linguistic resources, including NomBank and the Prague Czech-English Dependency\n",
            "Treebank 2.0 (PCEDT). We chose this dataset for two primary reasons: firstly, the dual annotation of\n",
            "relations on the same set of compounds is ideal for exploring TL and MTL approaches; secondly,\n",
            "aligning two different annotation frameworks on the same data allows for a comparative analysis\n",
            "across these frameworks.\n",
            "Specifically, we use a portion of the dataset, focusing on type-based instances of two-word compounds.\n",
            "The original dataset also encompasses multi-word compounds (those made up of more than two\n",
            "nouns) and multiple instances per compound type. We further divide the dataset into three parts:\n",
            "training, development, and test sets. Table 1 details the number of compound types and the vocabulary\n",
            "size for each set, including a breakdown of words appearing in the right-most (right constituents)\n",
            "and left-most (left constituents) positions. The two label sets consist of 35 PCEDT functors and 18\n",
            "2\n",
            "NomBank argument and adjunct relations. As discussed in Section 7.1, these label sets have a highly\n",
            "uneven distribution.\n",
            "Table 1: Characteristics of the noun-noun compound dataset used in our experiments. The numbers\n",
            "in this table correspond to a subset of the dataset, see Section 3.\n",
            "Train Dev Test\n",
            "Compounds 6932 920 1759\n",
            "V ocab size 4102 1163 1772\n",
            "Right constituents 2304 624 969\n",
            "Left constituents 2405 618 985\n",
            "Many relations in PCEDT and NomBank conceptually describe similar semantic ideas, as they are\n",
            "used to annotate the semantics of the same text. For instance, the temporal and locative relations in\n",
            "NomBank (ARGM-TMP and ARGM-LOC, respectively) and their PCEDT counterparts (TWHEN\n",
            "and LOC) exhibit relatively consistent behavior across frameworks, as they annotate many of the\n",
            "same compounds. However, some relations that are theoretically similar do not align well in practice.\n",
            "For example, the functor AIM in PCEDT and the modifier argument ARGM-PNC in NomBank\n",
            "express a somewhat related semantic concept (purpose), but there is minimal overlap between the\n",
            "sets of compounds they annotate. Nevertheless, it is reasonable to assume that the semantic similarity\n",
            "in the label sets, where it exists, can be leveraged through transfer and multi-task learning, especially\n",
            "since the overall distribution of relations differs between the two frameworks.\n",
            "4 Transfer vs. Multi-Task Learning\n",
            "In this section, we employ the terminology and definitions established by Pan and Yang (2010) to\n",
            "articulate our framework for transfer and multi-task learning. Our classification task can be described\n",
            "in terms of all training pairs (X, Y) and a probability distribution P(X), where X represents the input\n",
            "feature space, Y denotes the set of all labels, and N is the training data size. The domain of a task is\n",
            "defined by X, P(X). Our goal is to learn a function f(X) that predicts Y based on the input features X.\n",
            "Considering two ML tasks, Ta and Tb, we would train two distinct models to learn separate functions\n",
            "fa and fb for predicting Ya and Yb in a single-task learning scenario. However, if Ta and Tb are\n",
            "related, either explicitly or implicitly, TL and MTL can enhance the generalization of either or both\n",
            "tasks. Two tasks are deemed related when their domains are similar but their label sets differ, or when\n",
            "their domains are dissimilar but their label sets are identical. Consequently, noun-noun compound\n",
            "interpretation using the dataset is well-suited for TL and MTL, as the training examples are identical,\n",
            "but the label sets are distinct.\n",
            "For clarity, we differentiate between transfer learning and multi-task learning in this paper, despite\n",
            "these terms sometimes being used interchangeably in the literature. We define TL as the utilization of\n",
            "parameters from a model trained on Ta to initialize another model for Tb. In contrast, MTL involves\n",
            "training parts of the same model to learn both Ta and Tb, essentially learning one set of parameters\n",
            "for both tasks. The concept is to train a single model simultaneously on both tasks, where one task\n",
            "introduces an inductive bias that aids the model in generalizing over the main task. It is important to\n",
            "note that this does not necessarily imply that we aim to use a single model to predict both label sets\n",
            "in practice.\n",
            "5 Neural Classification Models\n",
            "This section introduces the neural classification models utilized in our experiments. To discern the\n",
            "impact of TL and MTL, we initially present a single-task learning model, which acts as our baseline.\n",
            "Subsequently, we employ this same model to implement TL and MTL.\n",
            "5.1 Single-Task Learning Model\n",
            "In our single-task learning (STL) configuration, we train and fine-tune a feed-forward neural network\n",
            "inspired by the neural classifier proposed by Dima and Hinrichs (2015). This network comprises four\n",
            "layers: 1) an input layer, 2) an embedding layer, 3) a hidden layer, and 4) an output layer. The input\n",
            "3\n",
            "layer consists of two integers that indicate the indices of a compound’s constituents in the embedding\n",
            "layer, where the word embedding vectors are stored. These selected vectors are then passed to a fully\n",
            "connected hidden layer, the size of which matches the dimensionality of the word embedding vectors.\n",
            "Finally, a softmax function is applied to the output layer to select the most probable relation.\n",
            "The compound’s constituents are represented using a 300-dimensional word embedding model trained\n",
            "on an English Wikipedia dump and the English Gigaword Fifth Edition. The embedding model was\n",
            "trained by Fares et al. (2017). If a word is not found during lookup in the embedding model, we\n",
            "check if the word is uppercased and attempt to find the lowercase version. For hyphenated words\n",
            "not found in the embedding vocabulary, we split the word at the hyphen and average the vectors of\n",
            "its parts, if they are present in the vocabulary. If the word remains unrepresented after these steps, a\n",
            "designated vector for unknown words is employed.\n",
            "5.1.1 Architecture and Hyperparameters\n",
            "Our selection of hyperparameters is informed by multiple rounds of experimentation with the single-\n",
            "task learning model, as well as the choices made by prior work. The weights of the embedding layer\n",
            "are updated during the training of all models. We utilize the Adaptive Moment Estimation (Adam)\n",
            "optimization function across all models, with a learning rate set to 0.001. The loss function employed\n",
            "is the negative-log likelihood. A Sigmoid activation function is used for the units in the hidden layer.\n",
            "All models are trained with mini-batches of size five. The maximum number of epochs is capped\n",
            "at 50, but an early stopping criterion based on the model’s accuracy on the validation split is also\n",
            "implemented. This means that training is halted if the validation accuracy does not improve over five\n",
            "consecutive epochs. All models are implemented in Keras, using TensorFlow as the backend. The TL\n",
            "and MTL models are trained using the same hyperparameters as the STL model.\n",
            "5.2 Transfer Learning Models\n",
            "In our experiments, transfer learning involves training an STL model on PCEDT relations and then\n",
            "using some of its weights to initialize another model for NomBank relations. Given the neural\n",
            "classifier architecture detailed in Section 5.1, we identify three ways to implement TL: 1) TLE:\n",
            "Transferring the embedding layer weights, 2) TLH: Transferring the hidden layer weights, and 3)\n",
            "TLEH: Transferring both the embedding and hidden layer weights. Furthermore, we differentiate\n",
            "between transfer learning from PCEDT to NomBank and vice versa. This results in six setups,\n",
            "as shown in Table 2. We do not apply TL (or MTL) to the output layer because it is task- or\n",
            "dataset-specific.\n",
            "5.3 Multi-Task Learning Models\n",
            "In MTL, we train a single model to simultaneously learn both PCEDT and NomBank relations,\n",
            "meaning all MTL models have two objective functions and two output layers. We implement two\n",
            "MTL setups: MTLE, which features a shared embedding layer but two task-specific hidden layers,\n",
            "and MTLF, which has no task-specific layers aside from the output layer (i.e., both the embedding\n",
            "and hidden layers are shared). We distinguish between the auxiliary and main tasks based on which\n",
            "validation accuracy (NomBank’s or PCEDT’s) is monitored by the early stopping criterion. This\n",
            "leads to a total of four MTL models, as shown in Table 3.\n",
            "6 Experimental Results\n",
            "Tables 2 and 3 display the accuracies of the various TL and MTL models on the development and test\n",
            "splits for NomBank and PCEDT. The top row in both tables indicates the accuracy of the STL model.\n",
            "All models were trained solely on the training split. Several insights can be gleaned from these\n",
            "tables. Firstly, the accuracy of the STL models decreases when evaluated on the test split for both\n",
            "NomBank and PCEDT. Secondly, all TL models achieve improved accuracy on the NomBank test\n",
            "split, although transfer learning does not significantly enhance accuracy on the development split of\n",
            "the same dataset. The MTL models, especially MTLF, have a detrimental effect on the development\n",
            "accuracy of NomBank, yet we observe a similar improvement, as with TL, on the test split. Thirdly,\n",
            "both TL and MTL models demonstrate less consistent effects on PCEDT (on both development and\n",
            "test splits) compared to NomBank. For instance, all TL models yield an absolute improvement of\n",
            "4\n",
            "about 1.25 points in accuracy on NomBank, whereas in PCEDT, TLE clearly outperforms the other\n",
            "two TL models (TLE improves over the STL accuracy by 1.37 points).\n",
            "Table 2: Accuracy (%) of the transfer learning models.\n",
            "Model NomBank PCEDT\n",
            "Dev Test Dev Test\n",
            "STL 78.15 76.75 58.80 56.05\n",
            "TLE 78.37 78.05 59.57 57.42\n",
            "TLH 78.15 78.00 59.24 56.51\n",
            "TLEH 78.48 78.00 59.89 56.68\n",
            "Table 3: Accuracy (%) of the MTL models.\n",
            "Model NomBank PCEDT\n",
            "Dev Test Dev Test\n",
            "STL 78.15 76.75 58.80 56.05\n",
            "MTLE 77.93 78.45 59.89 56.96\n",
            "MTLF 76.74 78.51 58.91 56.00\n",
            "Overall, the STL models’ accuracy declines when tested on the NomBank and PCEDT test splits,\n",
            "compared to their performance on the development split. This could suggest overfitting, especially\n",
            "since our stopping criterion selects the model with the best performance on the development split.\n",
            "Conversely, TL and MTL enhance accuracy on the test splits, despite using the same stopping criterion\n",
            "as STL. We interpret this as an improvement in the models’ ability to generalize. However, since\n",
            "these improvements are relatively minor, we further analyze the results to understand if and how TL\n",
            "and MTL are beneficial.\n",
            "7 Results Analysis\n",
            "This section provides a detailed analysis of the models’ performance, drawing on insights from the\n",
            "dataset and the classification errors made by the models. The discussion in the following sections is\n",
            "primarily based on the results from the test split, as it is larger than the development split.\n",
            "7.1 Relation Distribution\n",
            "To illustrate the complexity of the task, we depict the distribution of the most frequent relations in\n",
            "NomBank and PCEDT across the three data splits in Figure 1. Notably, approximately 71.18% of the\n",
            "relations in the NomBank training split are of type ARG1 (prototypical patient), while 52.20% of the\n",
            "PCEDT relations are of type RSTR (an underspecified adnominal modifier). Such a highly skewed\n",
            "distribution makes learning some of the other relations more challenging, if not impossible in certain\n",
            "cases. In fact, out of the 15 NomBank relations observed in the test split, five are never predicted\n",
            "by any of the STL, TL, or MTL models. Similarly, of the 26 PCEDT relations in the test split, only\n",
            "six are predicted. However, the unpredicted relations are extremely rare in the training split (e.g., 23\n",
            "PCEDT functors appear less than 20 times), making it doubtful whether any ML model could learn\n",
            "them under any circumstances.\n",
            "Given this imbalanced distribution, it is evident that accuracy alone is insufficient to determine the\n",
            "best-performing model. Therefore, in the subsequent section, we report and analyze the F1 scores of\n",
            "the predicted NomBank and PCEDT relations across all STL, TL, and MTL models.\n",
            "7.2 Per-Relation F1 Scores\n",
            "Tables 4 and 5 present the per-relation F1 scores for NomBank and PCEDT, respectively. We only\n",
            "include results for relations that are actually predicted by at least one of the models.\n",
            "5\n",
            "Table 4: Per-label F1 score on the NomBank test split.\n",
            "A0 A1 A2 A3 LOC MNR TMP\n",
            "Count 132 1282 153 75 25 25 27\n",
            "STL 49.82 87.54 45.78 60.81 28.57 29.41 66.67\n",
            "TLE 55.02 87.98 41.61 60.14 27.91 33.33 63.83\n",
            "TLH 54.81 87.93 42.51 60.00 25.00 35.29 65.31\n",
            "TLEH 53.62 87.95 42.70 61.11 29.27 33.33 65.22\n",
            "MTLE 54.07 88.34 42.86 61.97 30.00 28.57 66.67\n",
            "MTLF 53.09 88.41 38.14 62.69 00.00 00.00 52.17\n",
            "Table 5: Per-label F1 score on the PCEDT test split.\n",
            "ACT TWHEN APP PAT REG RSTR\n",
            "Count 89 14 118 326 216 900\n",
            "STL 43.90 42.11 22.78 42.83 20.51 68.81\n",
            "TLE 49.37 70.97 27.67 41.60 30.77 69.67\n",
            "TLH 53.99 62.07 25.00 43.01 26.09 68.99\n",
            "TLEH 49.08 64.52 28.57 42.91 28.57 69.08\n",
            "MTLE 54.09 66.67 24.05 42.03 27.21 69.31\n",
            "MTLF 47.80 42.11 25.64 40.73 19.22 68.89\n",
            "Several noteworthy patterns emerge from Tables 4 and 5. Firstly, the MTLF model appears to be\n",
            "detrimental to both datasets, leading to significantly degraded F1 scores for four NomBank relations,\n",
            "including the locative modifier ARGM-LOC and the manner modifier ARGM-MNR (abbreviated as\n",
            "LOC and MNR in Table 4), which the model fails to predict altogether. This same model exhibits\n",
            "the lowest F1 score compared to all other models for two PCEDT relations: REG (expressing a\n",
            "circumstance) and PAT (patient). Considering that the MTLF model achieves the highest accuracy\n",
            "on the NomBank test split (as shown in Table 3), it becomes even more apparent that relying solely\n",
            "on accuracy scores is inadequate for evaluating the effectiveness of TL and MTL for this task and\n",
            "dataset.\n",
            "Secondly, with the exception of the MTLF model, all TL and MTL models consistently improve\n",
            "the F1 score for all PCEDT relations except PAT. Notably, the F1 scores for the relations TWHEN\n",
            "and ACT show a substantial increase compared to other PCEDT relations when only the embedding\n",
            "layer’s weights are shared (MTLE) or transferred (TLE). This outcome can be partially understood\n",
            "by examining the correspondence matrices between NomBank arguments and PCEDT functors,\n",
            "presented in Tables 7 and 6. These tables illustrate how PCEDT functors map to NomBank arguments\n",
            "in the training split (Table 6) and vice versa (Table 7). Table 6 reveals that 80% of the compounds\n",
            "annotated as TWHEN in PCEDT were annotated as ARGM-TMP in NomBank. Additionally, 47% of\n",
            "ACT (Actor) relations map to ARG0 (Proto-Agent) in NomBank. While this mapping is not as distinct\n",
            "as one might hope, it is still relatively high when compared to how other PCEDT relations map to\n",
            "ARG0. The correspondence matrices also demonstrate that the presumed theoretical similarities\n",
            "between NomBank and PCEDT relations do not always hold in practice. Nevertheless, even such\n",
            "imperfect correspondences can provide a training signal that assists the TL and MTL models in\n",
            "learning relations like TWHEN and ACT.\n",
            "Since the TLE model outperforms STL in predicting REG by ten absolute points, we examined\n",
            "all REG compounds correctly classified by TLE but misclassified by STL. We found that STL\n",
            "misclassified them as RSTR, indicating that TL from NomBank helps TLE recover from STL’s\n",
            "overgeneralization in RSTR prediction.\n",
            "The two NomBank relations that receive the highest boost in F1 score (about five absolute points)\n",
            "are ARG0 and ARGM-MNR, but the improvement in the latter corresponds to only one additional\n",
            "compound, which might be a chance occurrence. Overall, TL and MTL from NomBank to PCEDT\n",
            "are more helpful than the reverse. One explanation is that five PCEDT relations (including the four\n",
            "most frequent ones) map to ARG1 in NomBank in more than 60% of cases for each relation, as seen\n",
            "in the first rows of Tables 6 and 7. This suggests that the weights learned to predict PCEDT relations\n",
            "6\n",
            "Table 6: Correspondence matrix between PCEDT functors and NomBank arguments. Slots with ’-’\n",
            "indicate zero, 0.00 represents a very small number but not zero.\n",
            "A1 A2 A0 A3 LOC TMP MNR\n",
            "RSTR 0.70 0.11 0.06 0.06 0.02 0.01 0.02\n",
            "PAT 0.90 0.05 0.01 0.02 0.01 - 0.00\n",
            "REG 0.78 0.10 0.04 0.06 0.00 0.00 0.00\n",
            "APP 0.62 0.21 0.13 0.02 0.01 0.00 -\n",
            "ACT 0.47 0.03 0.47 0.01 0.01 - 0.01\n",
            "AIM 0.65 0.12 0.07 0.06 0.01 - -\n",
            "TWHEN 0.10 0.03 - - - 0.80 -\n",
            "Count 3617 1312 777 499 273 116 59\n",
            "Table 7: Correspondence matrix between NomBank arguments and PCEDT functors.\n",
            "RSTR PAT REG APP ACT AIM TWHEN\n",
            "A1 0.51 0.54 0.12 0.06 0.03 0.02 0.00\n",
            "A2 0.47 0.09 0.11 0.14 0.01 0.02 0.00\n",
            "A0 0.63 0.03 0.07 0.13 0.26 0.02 -\n",
            "A3 0.66 0.08 0.13 0.03 0.01 0.02 -\n",
            "LOC 0.36 0.07 0.02 0.05 0.03 0.01 -\n",
            "TMP 0.78 - 0.01 0.01 - - 0.01\n",
            "MNR 0.24 0.05 0.01 - 0.03 - -\n",
            "Count 4932 715 495 358 119 103 79\n",
            "offer little to no inductive bias for NomBank relations. Conversely, the mapping from NomBank to\n",
            "PCEDT shows that although many NomBank arguments map to RSTR in PCEDT, the percentages\n",
            "are lower, making the mapping more diverse and discriminative, which seems to aid TL and MTL\n",
            "models in learning less frequent PCEDT relations.\n",
            "To understand why the PCEDT functor AIM is never predicted despite being more frequent than\n",
            "TWHEN, we found that AIM is almost always misclassified as RSTR by all models. Furthermore,\n",
            "AIM and RSTR have the highest lexical overlap in the training set among all PCEDT relation pairs:\n",
            "78.35% of left constituents and 73.26% of right constituents of compounds annotated as AIM occur\n",
            "in other compounds annotated as RSTR. This explains the models’ inability to learn AIM but raises\n",
            "questions about their ability to learn relational representations, which we explore further in Section\n",
            "7.3.\n",
            "Table 8: Macro-average F1 score on the test split.\n",
            "Model NomBank PCEDT\n",
            "STL 52.66 40.15\n",
            "TLE 52.83 48.34\n",
            "TLH 52.98 46.52\n",
            "TLEH 53.31 47.12\n",
            "MTLE 53.21 47.23\n",
            "MTLF 42.07 40.73\n",
            "Finally, to demonstrate the benefits of TL and MTL for NomBank and PCEDT, we report the F1\n",
            "macro-average scores in Table 8. This is arguably the appropriate evaluation measure for imbalanced\n",
            "classification problems. Note that relations not predicted by any model are excluded from the macro-\n",
            "average calculation. Table 8 clearly shows that TL and MTL on the embedding layer yield significant\n",
            "improvements for PCEDT, with about a 7-8 point increase in macro-average F1, compared to just\n",
            "0.65 in the best case for NomBank.\n",
            "7\n",
            "7.3 Generalization on Unseen Compounds\n",
            "We now analyze the models’ ability to generalize to compounds not seen during training. Recent\n",
            "research suggests that gains in noun-noun compound interpretation using word embeddings and\n",
            "similar neural classification models might be due to lexical memorization. In other words, the models\n",
            "learn that specific nouns are strong indicators of specific relations. To assess the role of lexical\n",
            "memorization in our models, we quantify the number of unseen compounds that the STL, TL, and\n",
            "MTL models predict correctly.\n",
            "We differentiate between ’partly’ and ’completely’ unseen compounds. A compound is ’partly’\n",
            "unseen if one of its constituents (left or right) is not present in the training data. A ’completely’\n",
            "unseen compound is one where neither the left nor the right constituent appears in the training data.\n",
            "Overall, nearly 20% of the compounds in the test split have an unseen left constituent, about 16%\n",
            "have an unseen right constituent, and 4% are completely unseen. Table 9 compares the performance\n",
            "of the different models on these three groups in terms of the proportion of compounds misclassified\n",
            "in each group.\n",
            "Table 9: Generalization error on the subset of unseen compounds in the test split. L: Left constituent.\n",
            "R: Right constituent. L&R: Completely unseen.\n",
            "NomBank PCEDT\n",
            "Model L R L&R L R L&R\n",
            "Count 351 286 72 351 286 72\n",
            "STL 27.92 39.51 50.00 45.01 47.55 41.67\n",
            "TLE 25.93 36.71 48.61 43.87 47.55 41.67\n",
            "TLH 26.21 38.11 50.00 46.15 49.30 47.22\n",
            "TLEH 26.50 38.81 52.78 45.87 47.55 43.06\n",
            "MTLE 24.50 33.22 38.89 44.44 47.20 43.06\n",
            "MTLF 22.79 34.27 40.28 44.16 47.90 38.89\n",
            "Table 9 shows that Transfer Learning (TL) and Multi-Task Learning (MTL) approaches reduce\n",
            "generalization error in NomBank across all scenarios, with the exception of TLH and TLEH for\n",
            "completely unseen compounds, where error increases. The greatest error reductions are achieved\n",
            "by MTL models across all three types of unseen compounds. Specifically, MTLE reduces the error\n",
            "by approximately six points for compounds with unseen right constituents and by eleven points for\n",
            "fully unseen compounds. Moreover, MTLF reduces the error by five points when the left constituent\n",
            "is unseen. It’s important to interpret these results in conjunction with the Count row in Table 9 for\n",
            "a comprehensive view. For example, the eleven-point error decrease in fully unseen compounds\n",
            "represents eight compounds. In PCEDT, the largest error reduction is on unseen left constituents,\n",
            "which is about 1.14 points, corresponding to four compounds; it’s 0.35 on unseen right constituents\n",
            "(one compound) and 2.7 on fully unseen compounds, or two compounds.\n",
            "Upon manual inspection of compounds that led to substantial reductions in the generalization error,\n",
            "specifically within NomBank, we examined the distribution of relations within correctly predicted\n",
            "unseen compound sets. Compared to the STL model, MTLE reduces generalization error for\n",
            "completely unseen compounds by a total of eight compounds, of which seven are annotated with the\n",
            "relation ARG1, which is the most common in NomBank. Regarding the unseen right constituents,\n",
            "MTLE’s 24 improved compounds consist of 18 ARG1, 5 ARG0, and 1 ARG2 compounds. A\n",
            "similar pattern arises when examining TLE model improvements, where most gains come from better\n",
            "predictions of ARG1 and ARG0 relations.\n",
            "A large portion of unseen compounds, whether partly or entirely unseen, that were misclassified by\n",
            "every model, were not of type ARG1 in NomBank, or RSTR in PCEDT. This pattern, along with\n",
            "correctly predicted unseen compounds primarily annotated with the most common relations, suggests\n",
            "that classification models rely on lexical memorization to learn the compound relation interpretation.\n",
            "To better comprehend lexical memorization’s impact, we present the ratio of relation-specific con-\n",
            "stituents in both NomBank and PCEDT, as depicted in Figure 2. We define a relation-specific\n",
            "constituent as a left or right constituent that appears with only one specific relation within the training\n",
            "data. Its ratio is calculated as its proportion in the full set of left or right constituents for each\n",
            "8\n",
            "relation. Analyzing Figure 2 reveals that NomBank relations possess higher ratios of relation-specific\n",
            "constituents compared to PCEDT. This potentially makes learning the former easier if the model\n",
            "solely relies on lexical memorization. Additionally, ARGM-TMP in NomBank and TWHEN in\n",
            "PCEDT have distinctly high ratios compared to other relations in Figure 2. These relations also\n",
            "have the second-highest F1 score in their datasets—except for STL on PCEDT (see Tables 4 and\n",
            "5). Lexical memorization is therefore a likely cause of these high F1 scores. We also observed that\n",
            "lower ratios of relation-specific constituents correlate with lower F1 scores, such as APP and REG in\n",
            "PCEDT. Based on these insights, we can’t dismiss the possibility that our models show some degree\n",
            "of lexical memorization, despite manual analysis also presenting cases where models demonstrate\n",
            "generalization and correct predictions in situations where lexical memorization is impossible.\n",
            "8 Conclusion\n",
            "The application of transfer and multi-task learning in natural language processing has gained sig-\n",
            "nificant traction, yet considerable ambiguity persists regarding the effectiveness of particular task\n",
            "characteristics and experimental setups. This research endeavors to clarify the benefits of TL and\n",
            "MTL in the context of semantic interpretation of noun-noun compounds. By executing a sequence of\n",
            "minimally contrasting experiments and conducting thorough analysis of results and prediction errors,\n",
            "we demonstrate how both TL and MTL can mitigate the effects of class imbalance and drastically\n",
            "enhance predictions for low-frequency relations. Overall, our TL, and particularly our MTL models,\n",
            "are better at making predictions both quantitatively and qualitatively. Notably, the improvements are\n",
            "observed on the ’most challenging’ inputs that include at least one constituent that was not present in\n",
            "the training data. However, clear indications of ’lexical memorization’ effects are evident in our error\n",
            "analysis of unseen compounds.\n",
            "Typically, the transfer of representations or sharing between tasks is more effective at the embedding\n",
            "layers, which represent the model’s internal representation of the compound constituents. Furthermore,\n",
            "in multi-task learning, the complete sharing of model architecture across tasks degrades its capacity\n",
            "to generalize when it comes to less frequent relations.\n",
            "The dataset provided by Fares (2016) is an appealing resource for new neural approaches to compound\n",
            "interpretation because it links this sub-problem with broad-coverage semantic role labeling or\n",
            "semantic dependency parsing in PCEDT and NomBank. Future research will focus on incorporating\n",
            "additional natural language processing tasks defined using these frameworks to understand noun-noun\n",
            "compound interpretation using TL and MTL.\n",
            "9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_pdf_pages(pdf_path):\n",
        "  try:\n",
        "        reader=PyPDF2.PdfReader(pdf_file)\n",
        "        page_count = len(reader.pages)\n",
        "        if 4 <= page_count <= 12:\n",
        "          print(f\"File: {reader} -> Fine (Number of pages: {page_count})\")\n",
        "          return True\n",
        "        else:\n",
        "          if page_count < 4:\n",
        "            print(f\"File: {reader} -> Reject (Number of pages: {page_count}) RESEARCH PAPER IS TOO SHORT\")\n",
        "            return False\n",
        "          else:\n",
        "            print(f\"File: {reader} -> Reject (Number of pages: {page_count}) EXCEEDS THE RECOMMENDED COUNT\")\n",
        "          return False\n",
        "  except Exception as e:\n",
        "        return f\"Error: {e}\""
      ],
      "metadata": {
        "id": "iZb-f5e1vE-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_pdf_pages(pdf_file)"
      ],
      "metadata": {
        "id": "jf66sWHvxEz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21211c7d-c05b-4e91-cada-3d49274245e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: <PyPDF2._reader.PdfReader object at 0x78e3f8173a10> -> Fine (Number of pages: 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_text_path = \"output.txt\"\n",
        "# Save the extracted text to a file\n",
        "with open(output_text_path, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(text)"
      ],
      "metadata": {
        "id": "FcChaUQdPsA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define synonyms to map extracted headings to our desired keys.\n",
        "heading_synonyms = {\n",
        "    'abstract': 'abstract',\n",
        "    'related work': 'related work',\n",
        "    'introduction': 'introduction',\n",
        "    'methodology': 'methods',\n",
        "    'methods': 'methods',\n",
        "    'dataset': 'methods',\n",
        "    'results': 'experiments',\n",
        "    'experiments': 'experiments',\n",
        "    'conclusions': 'conclusion',\n",
        "    'conclusion': 'conclusion',\n",
        "    'appendix': 'appendix',\n",
        "    'appendices': 'appendix'\n",
        "}\n",
        "\n",
        "# Our target headings including the new \"abstract\" heading.\n",
        "target_headings = [\"abstract\", \"related work\",\"introduction\", \"methods\", \"experiments\", \"conclusion\"]\n",
        "\n",
        "# Initialize the dictionary with empty strings for each key.\n",
        "sections = {key: \"\" for key in target_headings}\n",
        "\n",
        "# Open and read the text file.\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "current_section = None\n",
        "\n",
        "# Regex pattern for a main heading line starting with a number (e.g., \"1 Introduction\" or \"2 Methodology\").\n",
        "numbered_heading_pattern = re.compile(r'^(\\d+)\\s+(.+)$')\n",
        "# Regex pattern for detecting a standalone \"abstract\" heading (case-insensitive).\n",
        "abstract_pattern = re.compile(r'^abstract$', re.IGNORECASE)\n",
        "\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "    if not line:\n",
        "        continue\n",
        "\n",
        "    # Check for a standalone \"abstract\" heading.\n",
        "    if abstract_pattern.match(line):\n",
        "        current_section = \"abstract\"\n",
        "        continue\n",
        "\n",
        "    # Check if the line looks like a numbered main heading.\n",
        "    match = numbered_heading_pattern.match(line)\n",
        "    if match:\n",
        "        _, title = match.groups()\n",
        "        title_norm = title.lower().strip()\n",
        "        mapped_key = None\n",
        "        # Check if any of our synonyms appear in the heading.\n",
        "        for syn, key in heading_synonyms.items():\n",
        "            if syn in title_norm:\n",
        "                mapped_key = key\n",
        "                break\n",
        "        # If the mapped key is one of our target sections, switch to that section.\n",
        "        if mapped_key in target_headings:\n",
        "            current_section = mapped_key\n",
        "            continue  # Skip adding the heading line itself.\n",
        "\n",
        "    # If a section has been set, add the current line to its content.\n",
        "    if current_section:\n",
        "        sections[current_section] += line + \" \"\n",
        "\n",
        "# Optionally, strip extra whitespace from each section.\n",
        "sections = {k: v.strip() for k, v in sections.items()}\n",
        "\n",
        "# Print the resulting mapping.\n",
        "for key, text in sections.items():\n",
        "    print(f\"--- {key.upper()} ---\")\n",
        "    print(text)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1ZyvezuSLpi",
        "outputId": "1ce51fb5-20cb-4bb4-a00b-9d554d9b556f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ABSTRACT ---\n",
            "This study examines the effectiveness of transfer learning and multi-task learning in the context of a complex semantic classification problem: understanding the meaning of noun-noun compounds. Through a series of detailed experiments and an in-depth analysis of errors, we demonstrate that employing transfer learning by initializing parameters and multi-task learning through parameter sharing enables a neural classification model to better generalize across a dataset characterized by a highly uneven distribution of semantic relationships. Furthermore, we illustrate how utilizing dual annotations, which involve two distinct sets of relations applied to the same compounds, can enhance the overall precision of a neural classifier and improve its F1 scores for less common yet more challenging semantic relations.\n",
            "\n",
            "--- RELATED WORK ---\n",
            "Approaches to interpreting noun-noun compounds differ based on the classification of compound relations, as well as the machine learning models and features employed to learn these relations. For instance, some define a broad set of relations, while others employ a more detailed classification. Some researchers challenge the idea that noun-noun compounds can be interpreted using a fixed, predetermined set of relations, proposing alternative methods based on paraphrasing. We center our attention on methods that frame the interpretation problem as a classification task involving a fixed, predetermined set of relations. Various machine learning models have been applied to this task, including nearest neighbor classifiers that use semantic similarity based on lexical resources, kernel-based methods like SVMs that utilize lexical and relational features, Maximum Entropy models that incorporate a wide range of lexical and surface form features, and neural networks that rely on word embeddings or combine word embeddings with path embeddings. Among these studies, some have utilized the same dataset. To our knowledge, TL and MTL have not been previously applied to compound interpretation. Therefore, we review prior research on TL and MTL in other NLP tasks. Several recent studies have conducted extensive experiments on the application of TL and MTL to a variety of NLP tasks, such as named entity recognition, semantic labeling, sentence-level sentiment classification, super-tagging, chunking, and semantic dependency parsing. The consensus among these studies is that the advantages of TL and MTL are largely contingent on the characteristics of the tasks involved, including the unevenness of the data distribution, the semantic relatedness between the source and target tasks, the learning trajectory of the auxiliary and main tasks (where target tasks that quickly reach a plateau benefit most from non-plateauing auxiliary tasks), and the structural similarity between the tasks. Besides differing in the NLP tasks they investigate, the aforementioned studies employ slightly varied definitions of TL and MTL. Our research aligns with certain studies in that we apply TL and MTL to learn different semantic annotations of noun-noun compounds using the same dataset. However, our experimental design is more akin to other work in that we experiment with initializing parameters across all layers of the neural network and concurrently train a single MTL model on two sets of relations.\n",
            "\n",
            "--- INTRODUCTION ---\n",
            "Noun-noun compound interpretation involves determining the semantic connection between two nouns (or noun phrases in multi-word compounds). For instance, in the compound \"street protest,\" the task is to identify the semantic relationship between \"street\" and \"protest,\" which is a locative relation in this example. Given the prevalence of noun-noun compounds in natural language and its significance to other natural language processing (NLP) tasks like question answering and information retrieval, understanding noun-noun compounds has been extensively studied in theoretical linguistics, psycholinguistics, and computational linguistics. In computational linguistics, noun-noun compound interpretation is typically treated as an automatic classification task. Various machine learning (ML) algorithms and models, such as Maximum Entropy, Support Vector Machines, and Neural Networks, have been employed to decipher the semantics of nominal compounds. These models utilize information from lexical semantics, like WordNet-based features, and distributional semantics, such as word embeddings. However, noun- noun compound interpretation remains a challenging NLP problem due to the high productivity of noun-noun compounding as a linguistic structure and the difficulty in deriving the semantics of noun-noun compounds from their constituents. Our research contributes to advancing NLP research on noun-noun compound interpretation through the application of transfer and multi-task learning. The application of transfer learning (TL) and multi-task learning (MTL) in NLP has gained significant attention in recent years, yielding varying outcomes based on the specific tasks, model architectures, and datasets involved. These varying results, combined with the fact that neither TL nor MTL has been previously applied to noun-noun compound interpretation, motivate our thorough empirical investigation into the use of TL and MTL for this task. Our aim is not only to add to the existing research on the effectiveness of TL and MTL for semantic NLP tasks generally but also to ascertain their specific advantages for compound interpretation. A key reason for utilizing multi-task learning is to enhance generalization by making use of the domain-specific details present in the training data of related tasks. In this study, we demonstrate that TL and MTL can serve as a form of regularization, enabling the prediction of infrequent relations within a dataset marked by a highly skewed distribution of relations. This dataset is particularly well-suited for TL and MTL experimentation, as elaborated in Section 3. Our contributions are summarized as follows: 1. Through meticulous analysis of results, we discover that TL and MTL, especially when applied to the embedding layer, enhance overall accuracy and F1 scores for less frequent relations in a highly skewed dataset, compared to a robust single-task learning baseline. 2. Although our research concentrates on TL and MTL, we present, to our knowledge, the first experimental results on the relatively recent dataset from Fares (2016).\n",
            "\n",
            "--- METHODS ---\n",
            "The objective of this task is to train a model to categorize the semantic relationships between pairs of nouns in a labeled dataset, where each pair forms a noun-noun compound. The complexity of this task is influenced by factors such as the label set used and its distribution. For the experiments detailed in this paper, we utilize a noun-noun compounds dataset that features compounds annotated with two distinct taxonomies of relations. This means that each noun-noun compound is associated with two different relations, each based on different linguistic theories. This dataset is derived from established linguistic resources, including NomBank and the Prague Czech-English Dependency Treebank 2.0 (PCEDT). We chose this dataset for two primary reasons: firstly, the dual annotation of relations on the same set of compounds is ideal for exploring TL and MTL approaches; secondly, aligning two different annotation frameworks on the same data allows for a comparative analysis across these frameworks. Specifically, we use a portion of the dataset, focusing on type-based instances of two-word compounds. The original dataset also encompasses multi-word compounds (those made up of more than two nouns) and multiple instances per compound type. We further divide the dataset into three parts: training, development, and test sets. Table 1 details the number of compound types and the vocabulary size for each set, including a breakdown of words appearing in the right-most (right constituents) and left-most (left constituents) positions. The two label sets consist of 35 PCEDT functors and 18 2 NomBank argument and adjunct relations. As discussed in Section 7.1, these label sets have a highly uneven distribution. Table 1: Characteristics of the noun-noun compound dataset used in our experiments. The numbers in this table correspond to a subset of the dataset, see Section 3. Train Dev Test Compounds 6932 920 1759 V ocab size 4102 1163 1772 Right constituents 2304 624 969 Left constituents 2405 618 985 Many relations in PCEDT and NomBank conceptually describe similar semantic ideas, as they are used to annotate the semantics of the same text. For instance, the temporal and locative relations in NomBank (ARGM-TMP and ARGM-LOC, respectively) and their PCEDT counterparts (TWHEN and LOC) exhibit relatively consistent behavior across frameworks, as they annotate many of the same compounds. However, some relations that are theoretically similar do not align well in practice. For example, the functor AIM in PCEDT and the modifier argument ARGM-PNC in NomBank express a somewhat related semantic concept (purpose), but there is minimal overlap between the sets of compounds they annotate. Nevertheless, it is reasonable to assume that the semantic similarity in the label sets, where it exists, can be leveraged through transfer and multi-task learning, especially since the overall distribution of relations differs between the two frameworks. 4 Transfer vs. Multi-Task Learning In this section, we employ the terminology and definitions established by Pan and Yang (2010) to articulate our framework for transfer and multi-task learning. Our classification task can be described in terms of all training pairs (X, Y) and a probability distribution P(X), where X represents the input feature space, Y denotes the set of all labels, and N is the training data size. The domain of a task is defined by X, P(X). Our goal is to learn a function f(X) that predicts Y based on the input features X. Considering two ML tasks, Ta and Tb, we would train two distinct models to learn separate functions fa and fb for predicting Ya and Yb in a single-task learning scenario. However, if Ta and Tb are related, either explicitly or implicitly, TL and MTL can enhance the generalization of either or both tasks. Two tasks are deemed related when their domains are similar but their label sets differ, or when their domains are dissimilar but their label sets are identical. Consequently, noun-noun compound interpretation using the dataset is well-suited for TL and MTL, as the training examples are identical, but the label sets are distinct. For clarity, we differentiate between transfer learning and multi-task learning in this paper, despite these terms sometimes being used interchangeably in the literature. We define TL as the utilization of parameters from a model trained on Ta to initialize another model for Tb. In contrast, MTL involves training parts of the same model to learn both Ta and Tb, essentially learning one set of parameters for both tasks. The concept is to train a single model simultaneously on both tasks, where one task introduces an inductive bias that aids the model in generalizing over the main task. It is important to note that this does not necessarily imply that we aim to use a single model to predict both label sets in practice. 5 Neural Classification Models This section introduces the neural classification models utilized in our experiments. To discern the impact of TL and MTL, we initially present a single-task learning model, which acts as our baseline. Subsequently, we employ this same model to implement TL and MTL. 5.1 Single-Task Learning Model In our single-task learning (STL) configuration, we train and fine-tune a feed-forward neural network inspired by the neural classifier proposed by Dima and Hinrichs (2015). This network comprises four layers: 1) an input layer, 2) an embedding layer, 3) a hidden layer, and 4) an output layer. The input 3 layer consists of two integers that indicate the indices of a compound’s constituents in the embedding layer, where the word embedding vectors are stored. These selected vectors are then passed to a fully connected hidden layer, the size of which matches the dimensionality of the word embedding vectors. Finally, a softmax function is applied to the output layer to select the most probable relation. The compound’s constituents are represented using a 300-dimensional word embedding model trained on an English Wikipedia dump and the English Gigaword Fifth Edition. The embedding model was trained by Fares et al. (2017). If a word is not found during lookup in the embedding model, we check if the word is uppercased and attempt to find the lowercase version. For hyphenated words not found in the embedding vocabulary, we split the word at the hyphen and average the vectors of its parts, if they are present in the vocabulary. If the word remains unrepresented after these steps, a designated vector for unknown words is employed. 5.1.1 Architecture and Hyperparameters Our selection of hyperparameters is informed by multiple rounds of experimentation with the single- task learning model, as well as the choices made by prior work. The weights of the embedding layer are updated during the training of all models. We utilize the Adaptive Moment Estimation (Adam) optimization function across all models, with a learning rate set to 0.001. The loss function employed is the negative-log likelihood. A Sigmoid activation function is used for the units in the hidden layer. All models are trained with mini-batches of size five. The maximum number of epochs is capped at 50, but an early stopping criterion based on the model’s accuracy on the validation split is also implemented. This means that training is halted if the validation accuracy does not improve over five consecutive epochs. All models are implemented in Keras, using TensorFlow as the backend. The TL and MTL models are trained using the same hyperparameters as the STL model. 5.2 Transfer Learning Models In our experiments, transfer learning involves training an STL model on PCEDT relations and then using some of its weights to initialize another model for NomBank relations. Given the neural classifier architecture detailed in Section 5.1, we identify three ways to implement TL: 1) TLE: Transferring the embedding layer weights, 2) TLH: Transferring the hidden layer weights, and 3) TLEH: Transferring both the embedding and hidden layer weights. Furthermore, we differentiate between transfer learning from PCEDT to NomBank and vice versa. This results in six setups, as shown in Table 2. We do not apply TL (or MTL) to the output layer because it is task- or dataset-specific. 5.3 Multi-Task Learning Models In MTL, we train a single model to simultaneously learn both PCEDT and NomBank relations, meaning all MTL models have two objective functions and two output layers. We implement two MTL setups: MTLE, which features a shared embedding layer but two task-specific hidden layers, and MTLF, which has no task-specific layers aside from the output layer (i.e., both the embedding and hidden layers are shared). We distinguish between the auxiliary and main tasks based on which validation accuracy (NomBank’s or PCEDT’s) is monitored by the early stopping criterion. This leads to a total of four MTL models, as shown in Table 3.\n",
            "\n",
            "--- EXPERIMENTS ---\n",
            "Tables 2 and 3 display the accuracies of the various TL and MTL models on the development and test splits for NomBank and PCEDT. The top row in both tables indicates the accuracy of the STL model. All models were trained solely on the training split. Several insights can be gleaned from these tables. Firstly, the accuracy of the STL models decreases when evaluated on the test split for both NomBank and PCEDT. Secondly, all TL models achieve improved accuracy on the NomBank test split, although transfer learning does not significantly enhance accuracy on the development split of the same dataset. The MTL models, especially MTLF, have a detrimental effect on the development accuracy of NomBank, yet we observe a similar improvement, as with TL, on the test split. Thirdly, both TL and MTL models demonstrate less consistent effects on PCEDT (on both development and test splits) compared to NomBank. For instance, all TL models yield an absolute improvement of 4 about 1.25 points in accuracy on NomBank, whereas in PCEDT, TLE clearly outperforms the other two TL models (TLE improves over the STL accuracy by 1.37 points). Table 2: Accuracy (%) of the transfer learning models. Model NomBank PCEDT Dev Test Dev Test STL 78.15 76.75 58.80 56.05 TLE 78.37 78.05 59.57 57.42 TLH 78.15 78.00 59.24 56.51 TLEH 78.48 78.00 59.89 56.68 Table 3: Accuracy (%) of the MTL models. Model NomBank PCEDT Dev Test Dev Test STL 78.15 76.75 58.80 56.05 MTLE 77.93 78.45 59.89 56.96 MTLF 76.74 78.51 58.91 56.00 Overall, the STL models’ accuracy declines when tested on the NomBank and PCEDT test splits, compared to their performance on the development split. This could suggest overfitting, especially since our stopping criterion selects the model with the best performance on the development split. Conversely, TL and MTL enhance accuracy on the test splits, despite using the same stopping criterion as STL. We interpret this as an improvement in the models’ ability to generalize. However, since these improvements are relatively minor, we further analyze the results to understand if and how TL and MTL are beneficial. This section provides a detailed analysis of the models’ performance, drawing on insights from the dataset and the classification errors made by the models. The discussion in the following sections is primarily based on the results from the test split, as it is larger than the development split. 7.1 Relation Distribution To illustrate the complexity of the task, we depict the distribution of the most frequent relations in NomBank and PCEDT across the three data splits in Figure 1. Notably, approximately 71.18% of the relations in the NomBank training split are of type ARG1 (prototypical patient), while 52.20% of the PCEDT relations are of type RSTR (an underspecified adnominal modifier). Such a highly skewed distribution makes learning some of the other relations more challenging, if not impossible in certain cases. In fact, out of the 15 NomBank relations observed in the test split, five are never predicted by any of the STL, TL, or MTL models. Similarly, of the 26 PCEDT relations in the test split, only six are predicted. However, the unpredicted relations are extremely rare in the training split (e.g., 23 PCEDT functors appear less than 20 times), making it doubtful whether any ML model could learn them under any circumstances. Given this imbalanced distribution, it is evident that accuracy alone is insufficient to determine the best-performing model. Therefore, in the subsequent section, we report and analyze the F1 scores of the predicted NomBank and PCEDT relations across all STL, TL, and MTL models. 7.2 Per-Relation F1 Scores Tables 4 and 5 present the per-relation F1 scores for NomBank and PCEDT, respectively. We only include results for relations that are actually predicted by at least one of the models. 5 Table 4: Per-label F1 score on the NomBank test split. A0 A1 A2 A3 LOC MNR TMP Count 132 1282 153 75 25 25 27 STL 49.82 87.54 45.78 60.81 28.57 29.41 66.67 TLE 55.02 87.98 41.61 60.14 27.91 33.33 63.83 TLH 54.81 87.93 42.51 60.00 25.00 35.29 65.31 TLEH 53.62 87.95 42.70 61.11 29.27 33.33 65.22 MTLE 54.07 88.34 42.86 61.97 30.00 28.57 66.67 MTLF 53.09 88.41 38.14 62.69 00.00 00.00 52.17 Table 5: Per-label F1 score on the PCEDT test split. ACT TWHEN APP PAT REG RSTR Count 89 14 118 326 216 900 STL 43.90 42.11 22.78 42.83 20.51 68.81 TLE 49.37 70.97 27.67 41.60 30.77 69.67 TLH 53.99 62.07 25.00 43.01 26.09 68.99 TLEH 49.08 64.52 28.57 42.91 28.57 69.08 MTLE 54.09 66.67 24.05 42.03 27.21 69.31 MTLF 47.80 42.11 25.64 40.73 19.22 68.89 Several noteworthy patterns emerge from Tables 4 and 5. Firstly, the MTLF model appears to be detrimental to both datasets, leading to significantly degraded F1 scores for four NomBank relations, including the locative modifier ARGM-LOC and the manner modifier ARGM-MNR (abbreviated as LOC and MNR in Table 4), which the model fails to predict altogether. This same model exhibits the lowest F1 score compared to all other models for two PCEDT relations: REG (expressing a circumstance) and PAT (patient). Considering that the MTLF model achieves the highest accuracy on the NomBank test split (as shown in Table 3), it becomes even more apparent that relying solely on accuracy scores is inadequate for evaluating the effectiveness of TL and MTL for this task and dataset. Secondly, with the exception of the MTLF model, all TL and MTL models consistently improve the F1 score for all PCEDT relations except PAT. Notably, the F1 scores for the relations TWHEN and ACT show a substantial increase compared to other PCEDT relations when only the embedding layer’s weights are shared (MTLE) or transferred (TLE). This outcome can be partially understood by examining the correspondence matrices between NomBank arguments and PCEDT functors, presented in Tables 7 and 6. These tables illustrate how PCEDT functors map to NomBank arguments in the training split (Table 6) and vice versa (Table 7). Table 6 reveals that 80% of the compounds annotated as TWHEN in PCEDT were annotated as ARGM-TMP in NomBank. Additionally, 47% of ACT (Actor) relations map to ARG0 (Proto-Agent) in NomBank. While this mapping is not as distinct as one might hope, it is still relatively high when compared to how other PCEDT relations map to ARG0. The correspondence matrices also demonstrate that the presumed theoretical similarities between NomBank and PCEDT relations do not always hold in practice. Nevertheless, even such imperfect correspondences can provide a training signal that assists the TL and MTL models in learning relations like TWHEN and ACT. Since the TLE model outperforms STL in predicting REG by ten absolute points, we examined all REG compounds correctly classified by TLE but misclassified by STL. We found that STL misclassified them as RSTR, indicating that TL from NomBank helps TLE recover from STL’s overgeneralization in RSTR prediction. The two NomBank relations that receive the highest boost in F1 score (about five absolute points) are ARG0 and ARGM-MNR, but the improvement in the latter corresponds to only one additional compound, which might be a chance occurrence. Overall, TL and MTL from NomBank to PCEDT are more helpful than the reverse. One explanation is that five PCEDT relations (including the four most frequent ones) map to ARG1 in NomBank in more than 60% of cases for each relation, as seen in the first rows of Tables 6 and 7. This suggests that the weights learned to predict PCEDT relations 6 Table 6: Correspondence matrix between PCEDT functors and NomBank arguments. Slots with ’-’ indicate zero, 0.00 represents a very small number but not zero. A1 A2 A0 A3 LOC TMP MNR RSTR 0.70 0.11 0.06 0.06 0.02 0.01 0.02 PAT 0.90 0.05 0.01 0.02 0.01 - 0.00 REG 0.78 0.10 0.04 0.06 0.00 0.00 0.00 APP 0.62 0.21 0.13 0.02 0.01 0.00 - ACT 0.47 0.03 0.47 0.01 0.01 - 0.01 AIM 0.65 0.12 0.07 0.06 0.01 - - TWHEN 0.10 0.03 - - - 0.80 - Count 3617 1312 777 499 273 116 59 Table 7: Correspondence matrix between NomBank arguments and PCEDT functors. RSTR PAT REG APP ACT AIM TWHEN A1 0.51 0.54 0.12 0.06 0.03 0.02 0.00 A2 0.47 0.09 0.11 0.14 0.01 0.02 0.00 A0 0.63 0.03 0.07 0.13 0.26 0.02 - A3 0.66 0.08 0.13 0.03 0.01 0.02 - LOC 0.36 0.07 0.02 0.05 0.03 0.01 - TMP 0.78 - 0.01 0.01 - - 0.01 MNR 0.24 0.05 0.01 - 0.03 - - Count 4932 715 495 358 119 103 79 offer little to no inductive bias for NomBank relations. Conversely, the mapping from NomBank to PCEDT shows that although many NomBank arguments map to RSTR in PCEDT, the percentages are lower, making the mapping more diverse and discriminative, which seems to aid TL and MTL models in learning less frequent PCEDT relations. To understand why the PCEDT functor AIM is never predicted despite being more frequent than TWHEN, we found that AIM is almost always misclassified as RSTR by all models. Furthermore, AIM and RSTR have the highest lexical overlap in the training set among all PCEDT relation pairs: 78.35% of left constituents and 73.26% of right constituents of compounds annotated as AIM occur in other compounds annotated as RSTR. This explains the models’ inability to learn AIM but raises questions about their ability to learn relational representations, which we explore further in Section 7.3. Table 8: Macro-average F1 score on the test split. Model NomBank PCEDT STL 52.66 40.15 TLE 52.83 48.34 TLH 52.98 46.52 TLEH 53.31 47.12 MTLE 53.21 47.23 MTLF 42.07 40.73 Finally, to demonstrate the benefits of TL and MTL for NomBank and PCEDT, we report the F1 macro-average scores in Table 8. This is arguably the appropriate evaluation measure for imbalanced classification problems. Note that relations not predicted by any model are excluded from the macro- average calculation. Table 8 clearly shows that TL and MTL on the embedding layer yield significant improvements for PCEDT, with about a 7-8 point increase in macro-average F1, compared to just 0.65 in the best case for NomBank. 7 7.3 Generalization on Unseen Compounds We now analyze the models’ ability to generalize to compounds not seen during training. Recent research suggests that gains in noun-noun compound interpretation using word embeddings and similar neural classification models might be due to lexical memorization. In other words, the models learn that specific nouns are strong indicators of specific relations. To assess the role of lexical memorization in our models, we quantify the number of unseen compounds that the STL, TL, and MTL models predict correctly. We differentiate between ’partly’ and ’completely’ unseen compounds. A compound is ’partly’ unseen if one of its constituents (left or right) is not present in the training data. A ’completely’ unseen compound is one where neither the left nor the right constituent appears in the training data. Overall, nearly 20% of the compounds in the test split have an unseen left constituent, about 16% have an unseen right constituent, and 4% are completely unseen. Table 9 compares the performance of the different models on these three groups in terms of the proportion of compounds misclassified in each group. Table 9: Generalization error on the subset of unseen compounds in the test split. L: Left constituent. R: Right constituent. L&R: Completely unseen. NomBank PCEDT Model L R L&R L R L&R Count 351 286 72 351 286 72 STL 27.92 39.51 50.00 45.01 47.55 41.67 TLE 25.93 36.71 48.61 43.87 47.55 41.67 TLH 26.21 38.11 50.00 46.15 49.30 47.22 TLEH 26.50 38.81 52.78 45.87 47.55 43.06 MTLE 24.50 33.22 38.89 44.44 47.20 43.06 MTLF 22.79 34.27 40.28 44.16 47.90 38.89 Table 9 shows that Transfer Learning (TL) and Multi-Task Learning (MTL) approaches reduce generalization error in NomBank across all scenarios, with the exception of TLH and TLEH for completely unseen compounds, where error increases. The greatest error reductions are achieved by MTL models across all three types of unseen compounds. Specifically, MTLE reduces the error by approximately six points for compounds with unseen right constituents and by eleven points for fully unseen compounds. Moreover, MTLF reduces the error by five points when the left constituent is unseen. It’s important to interpret these results in conjunction with the Count row in Table 9 for a comprehensive view. For example, the eleven-point error decrease in fully unseen compounds represents eight compounds. In PCEDT, the largest error reduction is on unseen left constituents, which is about 1.14 points, corresponding to four compounds; it’s 0.35 on unseen right constituents (one compound) and 2.7 on fully unseen compounds, or two compounds. Upon manual inspection of compounds that led to substantial reductions in the generalization error, specifically within NomBank, we examined the distribution of relations within correctly predicted unseen compound sets. Compared to the STL model, MTLE reduces generalization error for completely unseen compounds by a total of eight compounds, of which seven are annotated with the relation ARG1, which is the most common in NomBank. Regarding the unseen right constituents, MTLE’s 24 improved compounds consist of 18 ARG1, 5 ARG0, and 1 ARG2 compounds. A similar pattern arises when examining TLE model improvements, where most gains come from better predictions of ARG1 and ARG0 relations. A large portion of unseen compounds, whether partly or entirely unseen, that were misclassified by every model, were not of type ARG1 in NomBank, or RSTR in PCEDT. This pattern, along with correctly predicted unseen compounds primarily annotated with the most common relations, suggests that classification models rely on lexical memorization to learn the compound relation interpretation. To better comprehend lexical memorization’s impact, we present the ratio of relation-specific con- stituents in both NomBank and PCEDT, as depicted in Figure 2. We define a relation-specific constituent as a left or right constituent that appears with only one specific relation within the training data. Its ratio is calculated as its proportion in the full set of left or right constituents for each 8 relation. Analyzing Figure 2 reveals that NomBank relations possess higher ratios of relation-specific constituents compared to PCEDT. This potentially makes learning the former easier if the model solely relies on lexical memorization. Additionally, ARGM-TMP in NomBank and TWHEN in PCEDT have distinctly high ratios compared to other relations in Figure 2. These relations also have the second-highest F1 score in their datasets—except for STL on PCEDT (see Tables 4 and 5). Lexical memorization is therefore a likely cause of these high F1 scores. We also observed that lower ratios of relation-specific constituents correlate with lower F1 scores, such as APP and REG in PCEDT. Based on these insights, we can’t dismiss the possibility that our models show some degree of lexical memorization, despite manual analysis also presenting cases where models demonstrate generalization and correct predictions in situations where lexical memorization is impossible.\n",
            "\n",
            "--- CONCLUSION ---\n",
            "The application of transfer and multi-task learning in natural language processing has gained sig- nificant traction, yet considerable ambiguity persists regarding the effectiveness of particular task characteristics and experimental setups. This research endeavors to clarify the benefits of TL and MTL in the context of semantic interpretation of noun-noun compounds. By executing a sequence of minimally contrasting experiments and conducting thorough analysis of results and prediction errors, we demonstrate how both TL and MTL can mitigate the effects of class imbalance and drastically enhance predictions for low-frequency relations. Overall, our TL, and particularly our MTL models, are better at making predictions both quantitatively and qualitatively. Notably, the improvements are observed on the ’most challenging’ inputs that include at least one constituent that was not present in the training data. However, clear indications of ’lexical memorization’ effects are evident in our error analysis of unseen compounds. Typically, the transfer of representations or sharing between tasks is more effective at the embedding layers, which represent the model’s internal representation of the compound constituents. Furthermore, in multi-task learning, the complete sharing of model architecture across tasks degrades its capacity to generalize when it comes to less frequent relations. The dataset provided by Fares (2016) is an appealing resource for new neural approaches to compound interpretation because it links this sub-problem with broad-coverage semantic role labeling or semantic dependency parsing in PCEDT and NomBank. Future research will focus on incorporating additional natural language processing tasks defined using these frameworks to understand noun-noun compound interpretation using TL and MTL. 9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing bigger sections\n"
      ],
      "metadata": {
        "id": "LgGHxhaVQcSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text, target_words=200):\n",
        "    \"\"\"\n",
        "    Summarizes the given text to around the specified target word count,\n",
        "    preserving technical information by prioritizing sentences with important terms.\n",
        "    \"\"\"\n",
        "    sentences = sent_tokenize(text)\n",
        "    if not sentences:\n",
        "        return text\n",
        "\n",
        "    # Tokenize words and remove stopwords to identify significant terms\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "\n",
        "    # Calculate word frequency to determine importance\n",
        "    word_freq = nltk.FreqDist(filtered_words)\n",
        "\n",
        "    # Score sentences based on the sum of word frequencies\n",
        "    sentence_scores = {}\n",
        "    for idx, sentence in enumerate(sentences):\n",
        "        for word in word_tokenize(sentence.lower()):\n",
        "            if word in word_freq:\n",
        "                sentence_scores[idx] = sentence_scores.get(idx, 0) + word_freq[word]\n",
        "\n",
        "    # Sort sentences by their scores in descending order\n",
        "    sorted_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    selected_indices = []\n",
        "    current_word_count = 0\n",
        "    for idx, score in sorted_sentences:\n",
        "        sentence = sentences[idx]\n",
        "        sentence_words = word_tokenize(sentence)\n",
        "        sentence_word_count = len(sentence_words)\n",
        "\n",
        "        if current_word_count + sentence_word_count <= target_words:\n",
        "            selected_indices.append(idx)\n",
        "            current_word_count += sentence_word_count\n",
        "        else:\n",
        "            remaining = target_words - current_word_count\n",
        "            if remaining > 0:\n",
        "                # Add partial sentence if it contributes significantly (optional)\n",
        "                selected_indices.append(idx)\n",
        "                current_word_count += sentence_word_count  # May exceed slightly\n",
        "            break\n",
        "\n",
        "    # Sort selected indices to maintain original order for coherence\n",
        "    selected_indices = sorted(selected_indices)\n",
        "    summary = ' '.join([sentences[i] for i in selected_indices])\n",
        "\n",
        "    # Ensure the summary is close to the target word count\n",
        "    summary_words = word_tokenize(summary)\n",
        "    if len(summary_words) > target_words:\n",
        "        summary = ' '.join(summary_words[:target_words])\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "R57CXOzz2KkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_sections(sections_dict):\n",
        "    \"\"\"\n",
        "    function iterates through each entry in the dictionary, using word_tokenize to accurately count words\n",
        "    \"\"\"\n",
        "    for key in sections_dict:\n",
        "        content = sections_dict[key]\n",
        "        words = word_tokenize(content)\n",
        "        if len(words) > 350:\n",
        "            summarized_content = summarize_text(content)\n",
        "            sections_dict[key] = summarized_content\n",
        "    return sections_dict"
      ],
      "metadata": {
        "id": "6ZjN6zEv2Rhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sections=process_sections(sections)\n",
        "print(sections['abstract'])\n",
        "print('-----------')\n",
        "print(sections['methods'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cseR_5ol2SQk",
        "outputId": "e8e4ffca-99d5-4feb-d48d-2f726600dc78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This study examines the effectiveness of transfer learning and multi-task learning in the context of a complex semantic classification problem: understanding the meaning of noun-noun compounds. Through a series of detailed experiments and an in-depth analysis of errors, we demonstrate that employing transfer learning by initializing parameters and multi-task learning through parameter sharing enables a neural classification model to better generalize across a dataset characterized by a highly uneven distribution of semantic relationships. Furthermore, we illustrate how utilizing dual annotations, which involve two distinct sets of relations applied to the same compounds, can enhance the overall precision of a neural classifier and improve its F1 scores for less common yet more challenging semantic relations.\n",
            "-----------\n",
            "We chose this dataset for two primary reasons : firstly , the dual annotation of relations on the same set of compounds is ideal for exploring TL and MTL approaches ; secondly , aligning two different annotation frameworks on the same data allows for a comparative analysis across these frameworks . 5.2 Transfer Learning Models In our experiments , transfer learning involves training an STL model on PCEDT relations and then using some of its weights to initialize another model for NomBank relations . Given the neural classifier architecture detailed in Section 5.1 , we identify three ways to implement TL : 1 ) TLE : Transferring the embedding layer weights , 2 ) TLH : Transferring the hidden layer weights , and 3 ) TLEH : Transferring both the embedding and hidden layer weights . 5.3 Multi-Task Learning Models In MTL , we train a single model to simultaneously learn both PCEDT and NomBank relations , meaning all MTL models have two objective functions and two output layers . We implement two MTL setups : MTLE , which features a shared embedding layer but two task-specific hidden layers , and MTLF , which has no task-specific layers aside from\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOADING LLM**"
      ],
      "metadata": {
        "id": "2GLpe6kDcQ38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zs2AlkbG3er",
        "outputId": "8650d2cf-19b5-4762-9dce-dbf356960b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `data titans` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `data titans`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "id": "6lDxsu12scpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd1bff9-24a6-4b4f-c0d1-36d097673b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gc\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "aOBAF39lsg1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"google/gemma-3-4b-it\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,device_map=\"auto\",\n",
        "    torch_dtype=\"bfloat16\",\n",
        "    attn_implementation=\"sdpa\"\n",
        "\n",
        ")\n",
        "# Load tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "chat_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    temperature=0.5,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    model_kwargs={\"use_cache\": True}  # Critical for speed\n",
        ")\n"
      ],
      "metadata": {
        "id": "wAQBxraQEq75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577,
          "referenced_widgets": [
            "e78d139aadb04118805c5b629c13d5d7",
            "df1320b5c5b14e1f9a52ea64a576d00e",
            "f3160d5ae44c4f3ca1e152bc6a25cf90",
            "80a533b534604056b065d7a27cbca492",
            "210f64dfba3f4471ad2f862a1e0a8db4",
            "d888eb79b4e24ba990c367c3235c4710",
            "0edcc2f578064270abd01ba9f2bdcbd9",
            "1c1a94f39e9f4b6f92252d7bcc6bbc8d",
            "ec78c251118546adb5a3f50ca8235940",
            "4b1a3d280f9148edaed3917308a87bd5",
            "6c35edb7cd2740beb40d42ad7a994853",
            "93ec26a093ec4595a58e919e8d4379e3",
            "238a96c8b87a4168b0a8f4306d00b1a3",
            "1cd26d5e38664798b57d6b84d3560bc4",
            "3a22812976904e65befa066b255c27b9",
            "dfaa090bdc0f4eb785dc69b9a7848972",
            "ec86e9291b414ffdb6fd1a5c75e9dbfe",
            "282f8628e3ba460d8f510552ae3c33d1",
            "b36ec081b7094e94855509223c7fba5b",
            "94f0cd1fb805454f8de2141ce628ce78",
            "eddd2cfe907e41de86c4bcff67d5c5a1",
            "7cbde966d9d4472084dd281cc3ce5bf6",
            "a07b00ccac954e4d895a637f18ca9774",
            "8019b854428e4379bdd2f0e3566df599",
            "c3385c1a3c70414792660d8a7d99f121",
            "6a7ab6e5be1c43cd95d058922111f170",
            "6ccdfcebd330487fb6351000549eab30",
            "35f4a54e7b4344f4a8eff4524352aed3",
            "32a8324f06534b6dbc34819c1d013cd4",
            "1eb897b616804603a4f750e4d4e9aa10",
            "5984f06117ad49fd8af5838f75bb394c",
            "775730b30eb94ab38e4fdb612cc0a442",
            "9372e092a9e8441aae72cd8bac76dbd6",
            "ca26e2b3aa8a4202bde0385eab31b51e",
            "29747d46ac5142e481ca04bef207dc85",
            "a3303098633642ce941a19fdfe3c29a9",
            "fbe2076dec73413e8a22944a009a30ed",
            "22c06a1f42e24a99a7dc18a7d373c383",
            "33a40a2586464bb7954402b0acc24c1c",
            "1b152bb8cf4b44efa37631fccd2ec0ed",
            "7152b307e7ea4f999d550ed2664f93fd",
            "c8c2f53076654f98b99e2a6bc0cab3d7",
            "db7dec6260ea426c985b9833fedb1e8b",
            "0ae9eec48d1c48e58a5a8e31ccc7dc5c",
            "9c18338b3bff470b926662c5e8a1e70a",
            "52994d841f6c491fb870ac1477a970fb",
            "3f4ee498fbc1478ea6541b19da399779",
            "7c18a70f602247f18b992d91515c3c38",
            "f1b29d7af0f84b54bc75403ba4b548b6",
            "22d90ee41cb94f5a9181c89bff117e2e",
            "b60c2c80088b4cf99cd58b72794042bb",
            "18d24db9bcfc409698b037ed2ea2a410",
            "6c51beab3a4a49ad8bec1f8165edef81",
            "95ddd0c042d540309e89f7d9bf8779eb",
            "5c42906f31be459a884a1a36667a88f2",
            "00ce8febf67b45f6a6d8031f6cfbbc34",
            "7869a25f5f6c454ea76e32c17e51aff9",
            "7f727e71986e48c0aa62df073dca952f",
            "c3d6f630f200448f877e0c419f1cb151",
            "640e0364fbc54d27a2fc1d83eaf511e5",
            "505c01bf724f43c6911b6335883e235a",
            "a2e4b0c6a83740098fa6b5ebb7b26074",
            "ccf7803a6ac84172b0c5a8b15c6d7094",
            "60ad24e075f04b4d85ae7d2b0e414642",
            "54433e4c821440aba3cf74612a5ba4ae",
            "3bf8dabfc3fc43809152792a17e47e4a",
            "a175e7368a9d4181b0c20185e26a94b0",
            "5bfa588f3fea4f209b33dc7af7abb855",
            "ecb6fb54807c48638d5e1df63e7f31e2",
            "c1ace91385574e9da47a5f0f3fc7e4b0",
            "8ec154ab44b04b329e60266117f7e62c",
            "a23982d5aa204e35b1878f07cb34018b",
            "d197739a9fb34c6cace2927e5ea120f9",
            "25a06a0cee354aeb8825010fe5884574",
            "6e5d0c62aa22438cb8f1b16026df0f30",
            "40024186496e4005a08c3074eb4b1893",
            "03f67b6fcce04c6c90c7a0d348bd7a08",
            "9ec5230219a7482d9ce85309c95151b4",
            "6bbb4ff97e05405688f6628860262989",
            "da69c2ffd07849eaa9f73ed5a52a8f30",
            "09f570515e664e71b57e3f5465cc9001",
            "1e89eb857ef14110a53569c45ca1ec49",
            "dfd66dc6801b404d9d4021e87563eb17",
            "7debc5f1aecd42feaecb03dd25c30ded",
            "71b9991e5ee040bfa0f9345abb58ec2a",
            "4433eaa001e8493298a9bbbc384a8991",
            "23fe33f9f18447fb9954f1e028f36278",
            "500725f92cb14eda8b8454b43d1fc5b8",
            "539eda85ee37444784b4b76c130922c4",
            "796fe5334db84bcb8113a2ebcde22868",
            "ba1dadc8f1bc4cf682cfe8fb9fa874cd",
            "84690cf70ab74fc6b6e2dd7efcf0434c",
            "8a1571ded10c487793452399bd5b1e9a",
            "02ed343ab1c64e22ad13eb9291f8b5bc",
            "4cfc9c1839f247bfaabe946db4fa786e",
            "563da134116240a284b0319304158019",
            "7ab65fafb8e043a29f9366b8d7bcddcc",
            "47bc9498e3c548c2b9e1f7efd1e9a936",
            "08e7ac6ba1ee45048aa75beecbc36b08",
            "360d90ac9cf64300923825a808be9361",
            "7170cf0e9e6549c6abd4c33319165dc9",
            "eb7a98ce1d2843fc8fa02a0ac16ffcc2",
            "4937f65babdd4dffae6bbdc192b19a32",
            "8a1f2f6d46814ff1b301daec9e42fb06",
            "6420d97af71c4691b2fdb4939b42900b",
            "6e6af60efd414989b93a7c1133aca25a",
            "58ec8df50b744ab2a9eeadb695795d40",
            "1245f7ba07fa441ab198ff5175037a95",
            "438846de09b7404cac652f8b13d37984",
            "a0d2859e74b04713bb22c9b5be3b5cb3",
            "6d5e875247314e74802d4d453f39cafb",
            "ab19c4934687428fba0f1a74075d8016",
            "7587f7f0038f468c8c08242793bdbff0",
            "dbab1776d4564c1b8b0961053fbb57af",
            "eae40a27075b4c52bb6594d3478fb9bd",
            "1c664eaeebcb4638b8e7c12926011142",
            "d1f27f08338a4acaae06aca9a9ff391b",
            "b7410c5de4994c2790cd106c340e4ecc",
            "19d949567efa4cefb7c740296513de68",
            "374f86ffdd27452290ad3a4abc9c25c3",
            "df700a23ff6e4634a3ddad500a13e073",
            "2b946e8470234fab9350b27dfafe49ff",
            "25eb61c29095424292ea582de4971548",
            "b95be68026b04cfe9d1f7ab382e61e32",
            "c0cb7b723009415683474695c610cbe3",
            "19768ae18dcd4deca0309196085035da",
            "6a7e9d31d3614038b4933debe60de878",
            "98e90c1dc3f54940b60c7b860641b9db",
            "7d91cfce36b44993ac35997d2fb19c90",
            "03d6cedda65c44239667be2c4e928e91",
            "10369455c9e6432ea3715d53652a0407",
            "a4ef333ec81549ce9b25a246d3b3c1ce"
          ]
        },
        "outputId": "9c394297-a9db-47d2-8c45-6bbd914e8b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e78d139aadb04118805c5b629c13d5d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/modeling_auto.py:1682: FutureWarning: Loading a multimodal model with `AutoModelForCausalLM` is deprecated and will be removed in v5. `AutoModelForCausalLM` will be used to load only the text-to-text generation module.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93ec26a093ec4595a58e919e8d4379e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a07b00ccac954e4d895a637f18ca9774"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca26e2b3aa8a4202bde0385eab31b51e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c18338b3bff470b926662c5e8a1e70a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00ce8febf67b45f6a6d8031f6cfbbc34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a175e7368a9d4181b0c20185e26a94b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ec5230219a7482d9ce85309c95151b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "539eda85ee37444784b4b76c130922c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "360d90ac9cf64300923825a808be9361"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d5e875247314e74802d4d453f39cafb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b946e8470234fab9350b27dfafe49ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QnA**"
      ],
      "metadata": {
        "id": "Odtz0rsdQrDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checklist_questions = {\n",
        "    \"1a\":\"Whether the problem statement is clear, well-articulated, and addresses important issues in the field?\",\n",
        "    \"1b\": \"Do the authors describe the limitations of their work?\",\n",
        "    \"1c\": \"Do the authors discuss any potential societal impacts of their work?\",\n",
        "    \"1d\": \"Prior literature has been analysed? Is the work well motivated and appropriately grounded in theory?\",\n",
        "    \"2a\": \"If the authors include theoretical results, do the authors state the full set of assumptions of all theoretical results?\",\n",
        "    \"2b\": \"If the authors include theoretical results, do the authors include complete proofs of all theoretical results?\",\n",
        "    \"3a\": \"If the authors ran experiments, do the authors include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)?\",\n",
        "    \"3b\": \"If the authors ran experiments, do the authors specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?\",\n",
        "    \"3d\": \"If the authors ran experiments, do the authors include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?\",\n",
        "    \"4a\": \"If the authors use existing assets (e.g., code, data, models), do the authors cite the creators or mentioned the license of assests?\",\n",
        "    \"4c\": \"If the authors curate/release new assets (e.g., code, data, models), do the authors include any new assets either in the supplemental material or as a URL?\",\n",
        "    \"4d\": \"If the authors curate/release new assets (e.g., code, data, models), do the authors discuss whether and how consent was obtained from people whose data they are using/curating?\",\n",
        "    \"5a\": \"If the authors used crowdsourcing or conducted research with human subjects, do the authors include the full text of instructions given to participants and screenshots, if applicable?\"\n",
        "}\n",
        "\n",
        "# Map each checklist question to the sections to be used as context\n",
        "question_section_mapping = {\n",
        "    \"1a\":[\"abstract\"],\n",
        "    \"1b\": [\"conclusion\"],\n",
        "    \"1c\": [\"conclusion\",\"introduction\"],\n",
        "    \"1d\": [\"related work\",\"introduction\"],\n",
        "    \"2a\": [\"methods\"],\n",
        "    \"2b\": [\"methods\"],\n",
        "    \"3a\": [\"experiments\"],\n",
        "    \"3b\": [\"experiments\"],\n",
        "    \"3d\": [\"experiments\"],\n",
        "    \"4a\": [\"methods\"],\n",
        "    \"4b\": [\"methods\"],\n",
        "    \"4c\": [\"methods\"],\n",
        "    \"4d\": [\"methods\"],\n",
        "    \"5a\": [\"methods\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "C_nGOmupEItu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answers(prompts, max_new_tokens=250, temperature=0.5):\n",
        "    \"\"\"\n",
        "    Generates answers from the LLM for a list of prompts using batching.\n",
        "\n",
        "    Parameters:\n",
        "        prompts (list): List of prompt strings.\n",
        "        max_new_tokens (int): Maximum tokens to generate for each prompt.\n",
        "        temperature (float): Sampling temperature.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of generated answers, one per prompt.\n",
        "    \"\"\"\n",
        "    # Batch process the list of prompts\n",
        "    results = chat_pipeline(prompts, max_new_tokens=max_new_tokens, temperature=temperature,top_p=1.0)\n",
        "    answers = []\n",
        "    for prompt, result in zip(prompts, results):\n",
        "        generated_text = result[0]['generated_text']\n",
        "        # Remove the prompt from the generated text, if it is repeated in the output\n",
        "        answer = generated_text[len(prompt):].strip()\n",
        "        answers.append(answer)\n",
        "    return answers"
      ],
      "metadata": {
        "id": "LT_9jIpdiE-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_all_checklist_questions(sections_text):\n",
        "    \"\"\"\n",
        "    For each checklist question, combine the context from the corresponding sections,\n",
        "    generate an answer from the LLM (in batch), and return a dictionary mapping the checklist\n",
        "    question (key) to its answer (value).\n",
        "\n",
        "    Parameters:\n",
        "        sections_text (dict): A dictionary mapping section names to their extracted text.\n",
        "                              e.g., {\"introduction\": \"...\", \"methods\": \"...\", \"conclusion\": \"...\"}\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping each checklist question to its generated answer.\n",
        "    \"\"\"\n",
        "    prompts = []\n",
        "    questions_list = []  # to keep track of the question text for mapping later\n",
        "\n",
        "    for key, question in checklist_questions.items():\n",
        "        # Retrieve the sections that correspond to this question\n",
        "        section_keys = question_section_mapping.get(key, [])\n",
        "        context_parts = []\n",
        "        for sec in section_keys:\n",
        "            if sec in sections_text:\n",
        "                context_parts.append(f\"--- {sec.upper()} ---\\n{sections_text[sec]}\")\n",
        "            else:\n",
        "                print(f\"Warning: No text provided for section '{sec}'\")\n",
        "        context = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "        # Construct the prompt for the LLM\n",
        "        prompt = (\n",
        "            \"Below is context extracted from a research paper:\\n\\n\"\n",
        "            f\"{context}\\n\\n\"\n",
        "            \"Answer the following question with 'yes', 'no', or 'n/a' and provide a brief justification for your answer.\\n\"\n",
        "            f\"Question: {question}\\n\\n\"\n",
        "            \"Answer:\"\n",
        "        )\n",
        "        prompts.append(prompt)\n",
        "        questions_list.append(question)\n",
        "\n",
        "    # Generate answers in batch using the GPU\n",
        "    answers_batch = generate_answers(prompts)\n",
        "\n",
        "    # Map each question to its answer\n",
        "    answers = {}\n",
        "    for question, answer in zip(questions_list, answers_batch):\n",
        "        print(question, answer)\n",
        "        print('-------********-----------')\n",
        "        answers[question] = answer\n",
        "\n",
        "\n",
        "    return answers"
      ],
      "metadata": {
        "id": "LXOfcPFKGk91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict=answer_all_checklist_questions(sections)\n",
        "print(output_dict)"
      ],
      "metadata": {
        "id": "vb34hytZElJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3d77b2-9585-4f84-8591-884cbf5cc1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whether the problem statement is clear, well-articulated, and addresses important issues in the field? yes\n",
            "Justification: The abstract clearly states the problem being addressed (understanding the meaning of noun-noun compounds), the methods used (transfer learning and multi-task learning), the benefits observed (improved generalization, enhanced precision, and F1 scores), and the challenges encountered (uneven distribution of semantic relationships). It presents a focused and relevant research question.\n",
            "-------********-----------\n",
            "Do the authors describe the limitations of their work? yes\n",
            "Justification: The authors explicitly state, \"However, clear indications of ’lexical memorization’ effects are evident in our error analysis of unseen compounds,\" and \"Furthermore, in multi-task learning, the complete sharing of model architecture across tasks degrades its capacity to generalize when it comes to less frequent relations.\" These are clear descriptions of limitations.\n",
            "-------********-----------\n",
            "Do the authors discuss any potential societal impacts of their work? no\n",
            "Justification: The research paper focuses solely on the technical aspects of applying transfer and multi-task learning to noun-noun compound interpretation in NLP. There is no mention of any broader societal implications or potential impacts of this work beyond its contribution to the field of NLP.\n",
            "-------********-----------\n",
            "Prior literature has been analysed? Is the work well motivated and appropriately grounded in theory? yes\n",
            "Justification: The research paper explicitly states that \"The consensus among these studies is that the advantages of TL and MTL are largely contingent on the characteristics of the tasks involved...\" and \"Our aim is not only to add to the existing research on the effectiveness of TL and MTL for semantic NLP tasks generally but also to ascertain their specific advantages for compound interpretation.\" This demonstrates that the authors have reviewed prior work and are building upon it. The motivation for the research is clearly stated as a gap in the literature – no previous application of TL and MTL to noun-noun compound interpretation – and the work is grounded in the broader context of transfer learning and multi-task learning in NLP.\n",
            "-------********-----------\n",
            "If the authors include theoretical results, do the authors state the full set of assumptions of all theoretical results? no\n",
            "Justification: The context states that the authors are conducting experiments and comparing different transfer learning and multi-task learning approaches. It does not mention any theoretical results or assumptions.\n",
            "-------********-----------\n",
            "If the authors include theoretical results, do the authors include complete proofs of all theoretical results? no\n",
            "Justification: The context states that the paper explores TL and MTL approaches, but it doesn't mention that the authors provide theoretical results or complete proofs. It only mentions that they are exploring these approaches.\n",
            "-------********-----------\n",
            "If the authors ran experiments, do the authors include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? n/a\n",
            "Justification: The text does not explicitly state whether the authors provided code, data, or instructions. It only describes the experimental setup and results.\n",
            "-------********-----------\n",
            "If the authors ran experiments, do the authors specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? no\n",
            "Justification: The paper mentions the models (NomBank PCEDT, STL, TLE, TLH, MTLE, MTLF) and their performance on different test splits (development, test, and NomBank to PCEDT), but it does not provide specific details about the training process, such as the data splits, hyperparameters, or how they were chosen.\n",
            "-------********-----------\n",
            "If the authors ran experiments, do the authors include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? no\n",
            "Justification: The text describes the performance of different models on different datasets (NomBank, PCEDT, etc.) and their accuracy. It does not mention any information about the computational resources used to train or run these models.\n",
            "-------********-----------\n",
            "If the authors use existing assets (e.g., code, data, models), do the authors cite the creators or mentioned the license of assests? no\n",
            "Justification: The text does not provide any information about whether the authors cite the creators or mention the licenses of the assets they used. It only states that they chose a dataset for specific reasons related to its annotation.\n",
            "-------********-----------\n",
            "If the authors curate/release new assets (e.g., code, data, models), do the authors include any new assets either in the supplemental material or as a URL? yes\n",
            "Justification: The context states that the authors are exploring \"TL and MTL approaches\" using the dataset and \"transfer learning models.\" This implies that they are sharing their experimental setup and potentially some of the trained models, which would be included in the supplemental material or as a URL.\n",
            "-------********-----------\n",
            "If the authors curate/release new assets (e.g., code, data, models), do the authors discuss whether and how consent was obtained from people whose data they are using/curating? no\n",
            "Justification: The paper does not mention anything about obtaining consent from individuals whose data is being used. It focuses solely on the dataset, annotation frameworks, and transfer/multi-task learning approaches.\n",
            "-------********-----------\n",
            "If the authors used crowdsourcing or conducted research with human subjects, do the authors include the full text of instructions given to participants and screenshots, if applicable? no\n",
            "Justification: The text describes experiments with a dataset and model training, but does not mention any crowdsourcing or human subjects. Therefore, it's n/a to answer whether instructions or screenshots were included.\n",
            "-------********-----------\n",
            "{'Whether the problem statement is clear, well-articulated, and addresses important issues in the field?': 'yes\\nJustification: The abstract clearly states the problem being addressed (understanding the meaning of noun-noun compounds), the methods used (transfer learning and multi-task learning), the benefits observed (improved generalization, enhanced precision, and F1 scores), and the challenges encountered (uneven distribution of semantic relationships). It presents a focused and relevant research question.', 'Do the authors describe the limitations of their work?': 'yes\\nJustification: The authors explicitly state, \"However, clear indications of ’lexical memorization’ effects are evident in our error analysis of unseen compounds,\" and \"Furthermore, in multi-task learning, the complete sharing of model architecture across tasks degrades its capacity to generalize when it comes to less frequent relations.\" These are clear descriptions of limitations.', 'Do the authors discuss any potential societal impacts of their work?': 'no\\nJustification: The research paper focuses solely on the technical aspects of applying transfer and multi-task learning to noun-noun compound interpretation in NLP. There is no mention of any broader societal implications or potential impacts of this work beyond its contribution to the field of NLP.', 'Prior literature has been analysed? Is the work well motivated and appropriately grounded in theory?': 'yes\\nJustification: The research paper explicitly states that \"The consensus among these studies is that the advantages of TL and MTL are largely contingent on the characteristics of the tasks involved...\" and \"Our aim is not only to add to the existing research on the effectiveness of TL and MTL for semantic NLP tasks generally but also to ascertain their specific advantages for compound interpretation.\" This demonstrates that the authors have reviewed prior work and are building upon it. The motivation for the research is clearly stated as a gap in the literature – no previous application of TL and MTL to noun-noun compound interpretation – and the work is grounded in the broader context of transfer learning and multi-task learning in NLP.', 'If the authors include theoretical results, do the authors state the full set of assumptions of all theoretical results?': 'no\\nJustification: The context states that the authors are conducting experiments and comparing different transfer learning and multi-task learning approaches. It does not mention any theoretical results or assumptions.', 'If the authors include theoretical results, do the authors include complete proofs of all theoretical results?': \"no\\nJustification: The context states that the paper explores TL and MTL approaches, but it doesn't mention that the authors provide theoretical results or complete proofs. It only mentions that they are exploring these approaches.\", 'If the authors ran experiments, do the authors include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)?': 'n/a\\nJustification: The text does not explicitly state whether the authors provided code, data, or instructions. It only describes the experimental setup and results.', 'If the authors ran experiments, do the authors specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?': 'no\\nJustification: The paper mentions the models (NomBank PCEDT, STL, TLE, TLH, MTLE, MTLF) and their performance on different test splits (development, test, and NomBank to PCEDT), but it does not provide specific details about the training process, such as the data splits, hyperparameters, or how they were chosen.', 'If the authors ran experiments, do the authors include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?': 'no\\nJustification: The text describes the performance of different models on different datasets (NomBank, PCEDT, etc.) and their accuracy. It does not mention any information about the computational resources used to train or run these models.', 'If the authors use existing assets (e.g., code, data, models), do the authors cite the creators or mentioned the license of assests?': 'no\\nJustification: The text does not provide any information about whether the authors cite the creators or mention the licenses of the assets they used. It only states that they chose a dataset for specific reasons related to its annotation.', 'If the authors curate/release new assets (e.g., code, data, models), do the authors include any new assets either in the supplemental material or as a URL?': 'yes\\nJustification: The context states that the authors are exploring \"TL and MTL approaches\" using the dataset and \"transfer learning models.\" This implies that they are sharing their experimental setup and potentially some of the trained models, which would be included in the supplemental material or as a URL.', 'If the authors curate/release new assets (e.g., code, data, models), do the authors discuss whether and how consent was obtained from people whose data they are using/curating?': 'no\\nJustification: The paper does not mention anything about obtaining consent from individuals whose data is being used. It focuses solely on the dataset, annotation frameworks, and transfer/multi-task learning approaches.', 'If the authors used crowdsourcing or conducted research with human subjects, do the authors include the full text of instructions given to participants and screenshots, if applicable?': \"no\\nJustification: The text describes experiments with a dataset and model training, but does not mention any crowdsourcing or human subjects. Therefore, it's n/a to answer whether instructions or screenshots were included.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again calling LLM to generate the final review based on the QnA"
      ],
      "metadata": {
        "id": "QYEB9O4XrnM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_review_from_qna(output_dict, chat_pipeline, temperature=0.3):\n",
        "    \"\"\"\n",
        "    Generates a paper review based on a dictionary of checklist Q&A.\n",
        "\n",
        "    Parameters:\n",
        "        output_dict (dict): A dictionary where keys are checklist questions (or question keys)\n",
        "                            and values are the corresponding answers generated by the LLM.\n",
        "        chat_pipeline: The Hugging Face text-generation pipeline (or similar callable) for generating output\n",
        "        temperature (float): Sampling temperature for generation.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated review of the paper.\n",
        "    \"\"\"\n",
        "    # Constructing a prompt by combining each Q&A pair.\n",
        "    prompt = \"Below is the checklist Q&A for a research paper:\\n\"\n",
        "    for q, a in output_dict.items():\n",
        "        prompt += f\"\\nQ: {q}\\nA: {a}\\n\"\n",
        "\n",
        "    prompt += (\"\\n\"\n",
        "               \"You are a highly knowledgeable and meticulous reviewer for prestigious AI conferences. generate a comprehensive review of the paper.\"\n",
        "               \"Your review should  summarize in one pargraph some strengths and weaknesses of the paper and appreciate the strengths\"\n",
        "               \"and also Comment on experimental design and data presentation and Suggestions for improvements \")\n",
        "\n",
        "    # Generate the review using the provided text-generation pipeline.\n",
        "    result = chat_pipeline(prompt,max_new_tokens=700,do_sample=False, temperature=temperature)\n",
        "    generated_text = result[0]['generated_text']\n",
        "\n",
        "    # remove the prompt from the generated text as it is repeated.\n",
        "    review = generated_text[len(prompt):].strip()\n",
        "    return review"
      ],
      "metadata": {
        "id": "80g9Rn4KwaBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_review = generate_review_from_qna(output_dict, chat_pipeline)\n",
        "print(generated_review)"
      ],
      "metadata": {
        "id": "VFpVZnC40_U6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8516c0bb-af80-4a25-dd76-48282ca70e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's my review of the paper:\n",
            "\n",
            "This research paper presents a valuable exploration of applying transfer learning (TL) and multi-task learning (MTL) to the challenging task of noun-noun compound interpretation in Natural Language Processing. The paper’s strength lies in its clear articulation of the problem, a well-motivated approach based on established theories of TL and MTL, and a thorough examination of different model configurations. The authors effectively highlight the limitations of existing approaches and demonstrate the potential benefits of their proposed methods, particularly in terms of improved generalization and F1 scores. However, the paper suffers from a lack of detail regarding the experimental setup, including specific training hyperparameters, data splits, and computational resources utilized. The absence of code, data, and instructions hinders reproducibility and limits the broader impact of the research. Furthermore, the paper’s discussion of societal impacts is entirely absent, a notable oversight given the potential applications of this technology. While the authors acknowledge limitations, a more in-depth analysis of the observed errors and potential biases would strengthen the work. To improve the paper, the authors should provide detailed information about their experimental design, including hyperparameter tuning strategies, data preprocessing steps, and a comprehensive description of the computational resources employed. Sharing the code and data would significantly enhance the reproducibility and impact of the research. Finally, a brief discussion of potential societal implications, such as the impact on accessibility or the potential for misuse, would demonstrate a more holistic understanding of the research’s broader context.\n"
          ]
        }
      ]
    }
  ]
}